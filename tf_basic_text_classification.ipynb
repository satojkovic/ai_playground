{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf_basic_text_classification",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UIggEfCQZy9Q"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.__version__)"
      ],
      "metadata": {
        "id": "mI6jIh0WZ57z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://storage.googleapis.com/download.tensorflow.org/data/stack_overflow_16k.tar.gz\"\n",
        "dataset = tf.keras.utils.get_file('stack_overflow_16k', url, untar=True, cache_dir='.', cache_subdir='')"
      ],
      "metadata": {
        "id": "l4OFNbBcNofP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = 'train'"
      ],
      "metadata": {
        "id": "Jzs6LBx0avl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(train_dir)"
      ],
      "metadata": {
        "id": "q8KIc0wda16W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "seed = 42"
      ],
      "metadata": {
        "id": "KD1rRDX_bIet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_train_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "    'train', batch_size=batch_size, validation_split=0.2, subset='training', seed=seed\n",
        ")"
      ],
      "metadata": {
        "id": "ybI3hYW6bORF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Label 0 corresponds to\", raw_train_ds.class_names[0])\n",
        "print(\"Label 1 corresponds to\", raw_train_ds.class_names[1])"
      ],
      "metadata": {
        "id": "Qt8m6BmVbfvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_val_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "    'train', batch_size=batch_size, validation_split=0.2, subset='validation', seed=seed\n",
        ")"
      ],
      "metadata": {
        "id": "0Hg1u_KhbwRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_test_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "    'test', batch_size=batch_size\n",
        ")"
      ],
      "metadata": {
        "id": "6JpWVhRecezC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_standardization(input_data):\n",
        "  lowercase = tf.strings.lower(input_data)\n",
        "  stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n",
        "  return tf.strings.regex_replace(stripped_html, '[%s]' % re.escape(string.punctuation), '')"
      ],
      "metadata": {
        "id": "Y_nmZiyDcgcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_features = 10000 # vocabulary size\n",
        "sequence_length = 250\n",
        "\n",
        "vectorize_layer = tf.keras.layers.TextVectorization(\n",
        "    standardize=custom_standardization,\n",
        "    max_tokens = max_features,\n",
        "    output_mode='int', output_sequence_length=sequence_length\n",
        ")"
      ],
      "metadata": {
        "id": "2REjhVVLdnpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_text = raw_train_ds.map(lambda x, y: x)\n",
        "vectorize_layer.adapt(train_text)"
      ],
      "metadata": {
        "id": "B6lspcmUeCCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorize_text(text, label):\n",
        "  text = tf.expand_dims(text, -1)\n",
        "  return vectorize_layer(text), label"
      ],
      "metadata": {
        "id": "9X9vh-FYerMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_batch, label_batch = next(iter(raw_train_ds))\n",
        "first_review, first_label = text_batch[0], label_batch[0]\n",
        "print('review:', first_review)\n",
        "print('label:', raw_train_ds.class_names[first_label])\n",
        "print('vectorized_review:', vectorize_text(first_review, first_label))"
      ],
      "metadata": {
        "id": "h6-OqmXXe2mh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('1287 -->', vectorize_layer.get_vocabulary()[1287])\n",
        "print('0 -->', vectorize_layer.get_vocabulary()[0])\n",
        "print('vocab size:', len(vectorize_layer.get_vocabulary()))"
      ],
      "metadata": {
        "id": "hieQ0qb5fcWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = raw_train_ds.map(vectorize_text)\n",
        "val_ds = raw_val_ds.map(vectorize_text)\n",
        "test_ds = raw_test_ds.map(vectorize_text)"
      ],
      "metadata": {
        "id": "yKmN_GPkgAM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "8B-Y2OeSgcDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 16"
      ],
      "metadata": {
        "id": "-ON9VkAlhg_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Embedding(max_features + 1, embedding_dim), # (batch, sequence, embedding)\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.GlobalAveragePooling1D(),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(4)\n",
        "])"
      ],
      "metadata": {
        "id": "NQ_Z7NpYhlSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "5OEsqgrviB2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "metrics = ['accuracy']"
      ],
      "metadata": {
        "id": "75THD55BiEbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=losses, optimizer='adam', metrics=metrics)"
      ],
      "metadata": {
        "id": "hgutnceli0Xl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "history = model.fit(train_ds, validation_data=val_ds, epochs=epochs)"
      ],
      "metadata": {
        "id": "1Vbng8-Ti51o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = model.evaluate(test_ds)"
      ],
      "metadata": {
        "id": "_S6H1uJrjagS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('loss: {}, accuracy: {}'.format(loss, acc))"
      ],
      "metadata": {
        "id": "kWXcwwj7j3P-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_dict = history.history\n",
        "history_dict.keys()"
      ],
      "metadata": {
        "id": "79A55CLAj6Mx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history_dict['accuracy']\n",
        "val_acc = history_dict['val_accuracy']\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)"
      ],
      "metadata": {
        "id": "T-iQvAeVkE7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and Validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3zFJIQEgkgcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RuDYlbnSkxqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "export_model = tf.keras.Sequential([\n",
        "  vectorize_layer, \n",
        "  model, \n",
        "  layers.Activation('sigmoid')                                    \n",
        "])"
      ],
      "metadata": {
        "id": "Kgkyc98Uk12V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "export_model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "en_m9baIlS8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = export_model.evaluate(raw_test_ds)\n",
        "print(accuracy)"
      ],
      "metadata": {
        "id": "-6jrC8MMlceE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "examples = [\n",
        "  \"The is csharp!\",\n",
        "  \"The is java.\",\n",
        "  \"The is not python\"\n",
        "]\n",
        "\n",
        "export_model.predict(examples)"
      ],
      "metadata": {
        "id": "LGvLJfwNliRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xVYgylPglsDG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}