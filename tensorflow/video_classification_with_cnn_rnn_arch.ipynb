{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "video_classification_with_cnn_rnn_arch",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K75yjJ9PlcCz"
      },
      "outputs": [],
      "source": [
        "!pip install -q git+https://github.com/tensorflow/docs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://git.io/JGc31 -O ucf101_top5.tar.gz\n",
        "!tar xf ucf101_top5.tar.gz"
      ],
      "metadata": {
        "id": "EtvZCHcsmEUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow_docs.vis import embed\n",
        "from tensorflow import keras\n",
        "from imutils import paths\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import imageio\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "cjeUfbLNmJLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyper parameters"
      ],
      "metadata": {
        "id": "sv4qRK0PmRjU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 10\n",
        "\n",
        "MAX_SEQ_LENGTH = 20\n",
        "NUM_FEATURES = 2048"
      ],
      "metadata": {
        "id": "75j7fPdDmOK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preparation"
      ],
      "metadata": {
        "id": "0K8BUqvomaDz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "\n",
        "print(f'Total videos for training: {len(train_df)}')\n",
        "print(f'Total videos for test: {len(test_df)}')\n",
        "\n",
        "train_df.sample(5)"
      ],
      "metadata": {
        "id": "1wFCacCCmWcB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def crop_center_square(frame):\n",
        "  y, x = frame.shape[0:2]\n",
        "  min_dim = min(x, y)\n",
        "  start_x = (x // 2) - (min_dim // 2)\n",
        "  start_y = (y // 2) - (min_dim // 2)\n",
        "  return frame[start_y : start_y + min_dim, start_x : start_x + min_dim]"
      ],
      "metadata": {
        "id": "9CRqMN6TK6kN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_video(path, max_frames=0, resize=(IMG_SIZE, IMG_SIZE)):\n",
        "  cap = cv2.VideoCapture(path)\n",
        "  frames = []\n",
        "  try:\n",
        "    while True:\n",
        "      ret, frame = cap.read()\n",
        "      if not ret:\n",
        "        break\n",
        "      frame = crop_center_square(frame)\n",
        "      frame = cv2.resize(frame, resize)\n",
        "      frame = frame[:, :, [2, 1, 0]]\n",
        "      frames.append(frame)\n",
        "      if len(frames) == max_frames:\n",
        "        break\n",
        "  finally:\n",
        "    cap.release()\n",
        "  return np.array(frames)"
      ],
      "metadata": {
        "id": "zvMOh2G8MO-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert label of the videos to numerical values\n",
        "label_processor = keras.layers.StringLookup(\n",
        "  num_oov_indices=0, vocabulary=np.unique(train_df['tag'])\n",
        ")\n",
        "print(label_processor.get_vocabulary())"
      ],
      "metadata": {
        "id": "dxaWSpCa29V_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the CNN feature extractor"
      ],
      "metadata": {
        "id": "k50s_TOa2Ed-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_feature_extractor():\n",
        "  feature_extractor = keras.applications.InceptionV3(\n",
        "    weights='imagenet',\n",
        "    include_top=False,\n",
        "    pooling='avg',\n",
        "    input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
        "  )\n",
        "  preprocess_input = keras.applications.inception_v3.preprocess_input\n",
        "\n",
        "  inputs = keras.Input((IMG_SIZE, IMG_SIZE, 3))\n",
        "  preprocessed = preprocess_input(inputs)\n",
        "\n",
        "  outputs = feature_extractor(preprocessed)\n",
        "  return keras.Model(inputs, outputs, name='feature_extractor')"
      ],
      "metadata": {
        "id": "-cXmD4f3ms_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_extractor = build_feature_extractor()"
      ],
      "metadata": {
        "id": "Ez1d8C4P25vt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare all videos"
      ],
      "metadata": {
        "id": "06jjbdfXNZY8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_all_videos(df, root_dir):\n",
        "  num_samples = len(df)\n",
        "  video_paths = df['video_name'].values.tolist()\n",
        "  labels = df['tag'].values\n",
        "  labels = label_processor(labels[..., None]).numpy()\n",
        "\n",
        "  frame_masks = np.zeros((num_samples, MAX_SEQ_LENGTH), dtype='bool')\n",
        "  frame_features = np.zeros(\n",
        "      (num_samples, MAX_SEQ_LENGTH, NUM_FEATURES), dtype='float32'\n",
        "  )\n",
        "\n",
        "  for idx, path in enumerate(tqdm(video_paths)):\n",
        "    frames = load_video(os.path.join(root_dir, path))\n",
        "    frames = frames[None, ...] # add batch dimension\n",
        "\n",
        "    # Initialize placeholders to store the masks and features of the current video.\n",
        "    temp_frame_mask = np.zeros((1, MAX_SEQ_LENGTH), dtype='bool')\n",
        "    temp_frame_features = np.zeros(\n",
        "        (1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype='float32'\n",
        "    )\n",
        "\n",
        "    # Extract features from the frames of the current video.\n",
        "    for i, batch in enumerate(frames):\n",
        "      video_length = batch.shape[0]\n",
        "      length = min(MAX_SEQ_LENGTH, video_length)\n",
        "      for j in range(length):\n",
        "        temp_frame_features[i, j, :] = feature_extractor.predict(\n",
        "            batch[None, j, :]\n",
        "        )\n",
        "      temp_frame_mask[i, :length] = 1 # 1 = not masked (not padded), 0 = masked\n",
        "    \n",
        "    frame_features[idx,] = temp_frame_features.squeeze()\n",
        "    frame_masks[idx,] = temp_frame_mask.squeeze()\n",
        "\n",
        "  return (frame_features, frame_masks), labels"
      ],
      "metadata": {
        "id": "jvQnsmV4K4bL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, train_labels = prepare_all_videos(train_df, 'train')"
      ],
      "metadata": {
        "id": "-g3nl0-bPQrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data, test_labels = prepare_all_videos(test_df, 'test')"
      ],
      "metadata": {
        "id": "aZxQw9ZjRIeI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the sequence model"
      ],
      "metadata": {
        "id": "JPPQiZxi5bf9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sequence_model():\n",
        "  class_vocab = label_processor.get_vocabulary()\n",
        "\n",
        "  frame_features_input = keras.Input((MAX_SEQ_LENGTH, NUM_FEATURES))\n",
        "  mask_input = keras.Input((MAX_SEQ_LENGTH, ), dtype='bool')\n",
        "\n",
        "  # Refer to the following tutorial to understand the significance of using `mask`:\n",
        "  # https://keras.io/api/layers/recurrent_layers/gru/\n",
        "  x = keras.layers.GRU(16, return_sequences=True)(\n",
        "      frame_features_input, mask=mask_input\n",
        "  )\n",
        "  x = keras.layers.GRU(8)(x)\n",
        "  x = keras.layers.Dropout(0.4)(x)\n",
        "  x = keras.layers.Dense(8, activation='relu')(x)\n",
        "  output = keras.layers.Dense(len(class_vocab), activation='softmax')(x)\n",
        "\n",
        "  rnn_model = keras.Model([frame_features_input, mask_input], output)\n",
        "\n",
        "  rnn_model.compile(\n",
        "      loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy']\n",
        "  )\n",
        "  return rnn_model"
      ],
      "metadata": {
        "id": "ktI0B2aC3jdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_model = get_sequence_model()"
      ],
      "metadata": {
        "id": "jpUlc_3t7tcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_model.summary()"
      ],
      "metadata": {
        "id": "G6T1lHBt7y-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "DOHNTBH_O5mm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_training(seq_model):\n",
        "  filepath = './video_classifier/'\n",
        "  checkpoint = keras.callbacks.ModelCheckpoint(\n",
        "      filepath, save_weights_only=True, save_best_only=True, verbose=1\n",
        "  )\n",
        "\n",
        "  history = seq_model.fit(\n",
        "      [train_data[0], train_data[1]],\n",
        "      train_labels,\n",
        "      validation_split=0.3,\n",
        "      epochs=EPOCHS,\n",
        "      callbacks=[checkpoint]\n",
        "  )"
      ],
      "metadata": {
        "id": "tsy4j6VC709m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_training(seq_model)"
      ],
      "metadata": {
        "id": "9OT9cKWdQj4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_model.load_weights('./video_classifier/')"
      ],
      "metadata": {
        "id": "FtdbeKZrTL-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_, accuracy = seq_model.evaluate([test_data[0], test_data[1]], test_labels)"
      ],
      "metadata": {
        "id": "22HJcO1tUMDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Test accuracy: {round(accuracy * 100, 2)}%')"
      ],
      "metadata": {
        "id": "zyqdbWCVUicQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ],
      "metadata": {
        "id": "0IEuTtohaIHs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_single_video(frames):\n",
        "  frames = frames[None, ...]\n",
        "  frame_mask = np.zeros(shape=(1, MAX_SEQ_LENGTH,), dtype='bool')\n",
        "  frame_features = np.zeros(shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype='float32')\n",
        "\n",
        "  for i, batch in enumerate(frames):\n",
        "    video_length = batch.shape[0]\n",
        "    length = min(video_length, MAX_SEQ_LENGTH)\n",
        "    for j in range(length):\n",
        "      frame_features[i, j, :] = feature_extractor.predict(batch[None, j, :])\n",
        "    frame_mask[i, :length] = 1\n",
        "\n",
        "  return frame_features, frame_mask"
      ],
      "metadata": {
        "id": "r_f5AO9KUpPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sequence_prediction(path, seq_model):\n",
        "  class_vocab = label_processor.get_vocabulary()\n",
        "  frames = load_video(os.path.join('test', path))\n",
        "  frame_features, frame_mask = prepare_single_video(frames)\n",
        "  probs = seq_model.predict([frame_features, frame_mask])[0]\n",
        "\n",
        "  for i in np.argsort(probs)[::-1]:\n",
        "    print(f'  {class_vocab[i]}: {probs[i] * 100:5.2f}%')\n",
        "  return frames"
      ],
      "metadata": {
        "id": "x8fPM-1ebETZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This utility is for visualization.\n",
        "# Referenced from:\n",
        "# https://www.tensorflow.org/hub/tutorials/action_recognition_with_tf_hub\n",
        "def to_gif(images):\n",
        "  converted_images = images.astype(np.uint8)\n",
        "  imageio.mimsave('animation.gif', converted_images, fps=10)\n",
        "  return embed.embed_file('animation.gif')"
      ],
      "metadata": {
        "id": "viTxRc1qbtiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_video = np.random.choice(test_df['video_name'].values.tolist())\n",
        "print(f'Test video path: {test_video}')\n",
        "test_frames = sequence_prediction(test_video, seq_model)\n",
        "to_gif(test_frames)"
      ],
      "metadata": {
        "id": "OBE8qMA3b_SZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "b6I725hzcUza"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}