{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "id": "4zlFHtNbVSdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l /usr/lib/x86_64-linux-gnu/libcudnn.so*"
      ],
      "metadata": {
        "id": "2hlqlG3OU3Zw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /usr/include/cudnn_version.h | grep MAJOR -A 2"
      ],
      "metadata": {
        "id": "I-zKamopbA21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!echo $LD_LIBRARY_PATH"
      ],
      "metadata": {
        "id": "bahRRh3bVavr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ktBNz7HKxUS"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade pip\n",
        "# Installs the wheel compatible with CUDA 11 and cuDNN 8.2 or newer.\n",
        "# Note: wheels only available on linux.\n",
        "!pip install --upgrade \"jax[cuda]\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flax"
      ],
      "metadata": {
        "id": "Ot7UVoRW9HP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tqdm"
      ],
      "metadata": {
        "id": "iXtMFKHOYkvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import jax.dlpack\n",
        "from jax import grad, jit, vmap, random\n",
        "from jax import random\n",
        "from jax.example_libraries import stax, optimizers\n",
        "\n",
        "from tensorflow import keras\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "\n",
        "import time\n",
        "import numpy.random as npr\n",
        "import math\n",
        "\n",
        "from typing import Optional\n",
        "\n",
        "import optax\n",
        "from flax.training import train_state\n",
        "\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "MGT0h4ZRK3W2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ViT"
      ],
      "metadata": {
        "id": "iNmAau7872pm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flax import linen as nn"
      ],
      "metadata": {
        "id": "nIYx16Xv896d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Patches(nn.Module):\n",
        "  patch_size: int\n",
        "  embed_dim: int\n",
        "\n",
        "  def setup(self):\n",
        "    self.conv = nn.Conv(\n",
        "        features=self.embed_dim,\n",
        "        kernel_size=(self.patch_size, self.patch_size),\n",
        "        strides=(self.patch_size, self.patch_size),\n",
        "        padding='VALID'\n",
        "    )\n",
        "\n",
        "  def __call__(self, images):\n",
        "    patches = self.conv(images)\n",
        "    b, h, w, c = patches.shape\n",
        "    patches = jnp.reshape(patches, (b, h*w, c))\n",
        "    return patches"
      ],
      "metadata": {
        "id": "FmUlFQSBL1Gw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchEncoder(nn.Module):\n",
        "  hidden_dim: int\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, x):\n",
        "    assert x.ndim == 3\n",
        "    n, seq_len, _ = x.shape\n",
        "    # Hidden dim\n",
        "    x = nn.Dense(self.hidden_dim)(x)\n",
        "    # Add cls token\n",
        "    cls = self.param('cls_token', nn.initializers.zeros, (1, 1, self.hidden_dim))\n",
        "    cls = jnp.tile(cls, (n, 1, 1))\n",
        "    x = jnp.concatenate([cls, x], axis=1)\n",
        "    # Add position embedding\n",
        "    pos_embed = self.param(\n",
        "        'position_embedding', \n",
        "        nn.initializers.normal(stddev=0.02), # From BERT\n",
        "        (1, seq_len + 1, self.hidden_dim)\n",
        "    )\n",
        "    return x + pos_embed"
      ],
      "metadata": {
        "id": "vkA3rripeet2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadSelfAttention(nn.Module):\n",
        "  hidden_dim: int\n",
        "  n_heads: int\n",
        "  drop_p: float\n",
        "\n",
        "  def setup(self):\n",
        "    self.q_net = nn.Dense(self.hidden_dim)\n",
        "    self.k_net = nn.Dense(self.hidden_dim)\n",
        "    self.v_net = nn.Dense(self.hidden_dim)\n",
        "\n",
        "    self.proj_net = nn.Dense(self.hidden_dim)\n",
        "\n",
        "    self.att_drop = nn.Dropout(self.drop_p)\n",
        "    self.proj_drop = nn.Dropout(self.drop_p)\n",
        "\n",
        "  def __call__(self, x, train=True):\n",
        "    B, T, C = x.shape # batch_size, seq_length, hidden_dim\n",
        "    N, D = self.n_heads, C // self.n_heads # num_heads, head_dim\n",
        "    q = self.q_net(x).reshape(B, T, N, D).transpose(0, 2, 1, 3) # (B, N, T, D)\n",
        "    k = self.k_net(x).reshape(B, T, N, D).transpose(0, 2, 1, 3)\n",
        "    v = self.v_net(x).reshape(B, T, N, D).transpose(0, 2, 1, 3)\n",
        "\n",
        "    # weights (B, N, T, T)\n",
        "    weights = jnp.matmul(q, jnp.swapaxes(k, -2, -1)) / math.sqrt(D)\n",
        "    normalized_weights = nn.softmax(weights, axis=-1)\n",
        "\n",
        "    # attention (B, N, T, D)\n",
        "    attention = jnp.matmul(normalized_weights, v)\n",
        "    attention = self.att_drop(attention, deterministic=not train)\n",
        "\n",
        "    # gather heads\n",
        "    attention = attention.transpose(0, 2, 1, 3).reshape(B, T, N*D)\n",
        "\n",
        "    # project\n",
        "    out = self.proj_drop(self.proj_net(attention), deterministic=not train)\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "03qMlD1p72M8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "  mlp_dim: int\n",
        "  drop_p: float\n",
        "  out_dim: Optional[int] = None\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, inputs, train=True):\n",
        "    actual_out_dim = inputs.shape[-1] if self.out_dim is None else self.out_dim\n",
        "    x = nn.Dense(features=self.mlp_dim)(inputs)\n",
        "    x = nn.gelu(x)\n",
        "    x = nn.Dropout(rate=self.drop_p, deterministic=not train)(x)\n",
        "    x = nn.Dense(features=actual_out_dim)(x)\n",
        "    x = nn.Dropout(rate=self.drop_p, deterministic=not train)(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "yZ83UwjTQm9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn.Module):\n",
        "  embed_dim: int\n",
        "  hidden_dim: int\n",
        "  n_heads: int\n",
        "  drop_p: float\n",
        "  mlp_dim: int\n",
        "\n",
        "  def setup(self):\n",
        "    self.mha = MultiHeadSelfAttention(self.hidden_dim, self.n_heads, self.drop_p)\n",
        "    self.mlp = MLP(self.mlp_dim, self.drop_p)\n",
        "    self.layer_norm = nn.LayerNorm(epsilon=1e-6)\n",
        "    self.dropout = nn.Dropout(rate=self.drop_p)\n",
        "  \n",
        "  def __call__(self, inputs, train=True):\n",
        "    # Attention Block\n",
        "    x = self.layer_norm(inputs)\n",
        "    x = self.mha(x, train)\n",
        "    x = inputs + self.dropout(x, deterministic=not train)\n",
        "    # MLP block\n",
        "    y = self.layer_norm(x)\n",
        "    y = self.mlp(y, train)\n",
        "\n",
        "    return x + y"
      ],
      "metadata": {
        "id": "Oi4p-2JcHej8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ViT(nn.Module):\n",
        "  patch_size: int\n",
        "  embed_dim: int\n",
        "  hidden_dim: int\n",
        "  n_heads: int\n",
        "  drop_p: float\n",
        "  num_layers: int\n",
        "  mlp_dim: int\n",
        "  num_classes: int\n",
        "\n",
        "  def setup(self):\n",
        "    self.patch_extracter = Patches(self.patch_size, self.embed_dim)\n",
        "    self.patch_encoder = PatchEncoder(self.hidden_dim)\n",
        "    self.transformer = Transformer(self.embed_dim, self.hidden_dim, self.n_heads, self.drop_p, self.mlp_dim)\n",
        "    self.mlp_head = MLP(self.mlp_dim, self.drop_p)\n",
        "    self.cls_head = nn.Dense(features=self.num_classes)\n",
        "\n",
        "  def __call__(self, x, train=True):\n",
        "    x = self.patch_extracter(x)\n",
        "    x = self.patch_encoder(x)\n",
        "    for i in range(self.num_layers):\n",
        "      x = self.transformer(x, train)\n",
        "    # MLP head\n",
        "    x = x[:, 0] # [CLS] token\n",
        "    x = self.mlp_head(x, train)\n",
        "    x = self.cls_head(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "eq_xl6tFBrTj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize ViT"
      ],
      "metadata": {
        "id": "wCcAE57QLZss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "main_rng = jax.random.PRNGKey(42)\n",
        "x = jnp.ones(shape=(5, 32, 32, 3))\n",
        "# ViT\n",
        "model = ViT(\n",
        "    patch_size=4,\n",
        "    embed_dim=256,\n",
        "    hidden_dim=512,\n",
        "    n_heads=8,\n",
        "    drop_p=0.2,\n",
        "    num_layers=6,\n",
        "    mlp_dim=1024,\n",
        "    num_classes=10\n",
        ")\n",
        "main_rng, init_rng, drop_rng = random.split(main_rng, 3)\n",
        "params = model.init({'params': init_rng, 'dropout': drop_rng}, x, train=True)['params']"
      ],
      "metadata": {
        "id": "zCz8JPL2NY9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jax.tree_map(lambda x: x.shape, params)"
      ],
      "metadata": {
        "id": "w4FKGPAnLK1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create TrainState"
      ],
      "metadata": {
        "id": "mKOyOLvVSNck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def init_train_state(\n",
        "    model, params, learning_rate\n",
        "):\n",
        "  optimizer = optax.adam(learning_rate)\n",
        "  return train_state.TrainState.create(\n",
        "      apply_fn=model.apply,\n",
        "      tx=optimizer,\n",
        "      params=params\n",
        "  )"
      ],
      "metadata": {
        "id": "BQtd9GoQRFtJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state = init_train_state(model, params, 3e-4)"
      ],
      "metadata": {
        "id": "sXDI4K55Rdan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset preparation"
      ],
      "metadata": {
        "id": "X8-H3OQBZ3Ot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "import tensorflow_datasets as tfds"
      ],
      "metadata": {
        "id": "OhWeZXiEu49s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(full_train_set, test_dataset), ds_info = tfds.load(\n",
        "    'cifar10',\n",
        "    split=['train', 'test'],\n",
        "    shuffle_files=True,\n",
        "    as_supervised=True,\n",
        "    with_info=True\n",
        ")"
      ],
      "metadata": {
        "id": "OZyprjH7at3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_img(image, label):\n",
        "  image = tf.cast(image, tf.float32) / 255.0\n",
        "  return image, label"
      ],
      "metadata": {
        "id": "D606xZ3ha9nt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_train_set = full_train_set.map(\n",
        "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE\n",
        ")"
      ],
      "metadata": {
        "id": "N5Z6GWT2eQoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split train_set into train and val\n",
        "validation_split = 0.2\n",
        "num_data = tf.data.experimental.cardinality(full_train_set).numpy()\n",
        "train_dataset = full_train_set.take(\n",
        "    num_data * (1 - validation_split)\n",
        ")\n",
        "val_dataset = full_train_set.take(\n",
        "    num_data * validation_split\n",
        ")"
      ],
      "metadata": {
        "id": "o4PkYgYfebsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train_dataset.cache()\n",
        "train_dataset = train_dataset.shuffle(tf.data.experimental.cardinality(train_dataset).numpy())\n",
        "train_dataset = train_dataset.batch(64)"
      ],
      "metadata": {
        "id": "hvD3jALafEDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = val_dataset.cache()\n",
        "val_dataset = val_dataset.shuffle(tf.data.experimental.cardinality(val_dataset).numpy())\n",
        "val_dataset = val_dataset.batch(64)"
      ],
      "metadata": {
        "id": "ymXU-ESlgS11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = test_dataset.cache()\n",
        "test_dataset = test_dataset.shuffle(tf.data.experimental.cardinality(test_dataset).numpy())\n",
        "test_dataset = test_dataset.batch(64)"
      ],
      "metadata": {
        "id": "6rNtfdLcgjSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train step"
      ],
      "metadata": {
        "id": "gK1Eny56luxx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropy_loss(*, logits, labels):\n",
        "  labels_onehot = jax.nn.one_hot(labels, num_classes=10)\n",
        "  return optax.softmax_cross_entropy(logits=logits, labels=labels_onehot).mean()"
      ],
      "metadata": {
        "id": "KNQ0ghy4MwYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(*, logits, labels):\n",
        "  loss = cross_entropy_loss(logits=logits, labels=labels)\n",
        "  accuracy = jnp.mean(jnp.argmax(logits, -1) == labels)\n",
        "  metrics = {\n",
        "      'loss': loss,\n",
        "      'accuracy': accuracy,\n",
        "  }\n",
        "  return metrics"
      ],
      "metadata": {
        "id": "J8kUeBawNfer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@jax.jit\n",
        "def train_step(state, batch, rng):\n",
        "  images, labels = batch\n",
        "  rng, drop_rng = random.split(rng)\n",
        "\n",
        "  def loss_fn(params):\n",
        "    logits = state.apply_fn({'params': params}, images, rngs={'dropout': drop_rng})\n",
        "    loss = cross_entropy_loss(logits=logits, labels=labels)\n",
        "    return loss, logits\n",
        "\n",
        "  gradient_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
        "  (_, logits), grads = gradient_fn(state.params)\n",
        "  state = state.apply_gradients(grads=grads)\n",
        "  metrics = compute_metrics(logits=logits, labels=labels)\n",
        "  return state, metrics"
      ],
      "metadata": {
        "id": "Iu7XfO0Jm4VE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_dataset, state, epochs):\n",
        "  num_train_batches = tf.data.experimental.cardinality(train_dataset)\n",
        "  for epoch in tqdm(range(1, epochs + 1)):\n",
        "    train_datagen = iter(tfds.as_numpy(train_dataset))\n",
        "    for batch_idx in range(num_train_batches):\n",
        "      batch = next(train_datagen)\n",
        "      state, metrics = train_step(state, batch, main_rng)\n",
        "      print(f\"epoch {epoch}: acc {metrics['accuracy']}, loss {metrics['loss']}\")"
      ],
      "metadata": {
        "id": "67bcAybZNo7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(train_dataset, state, 10)"
      ],
      "metadata": {
        "id": "uczKlNt0adH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "itKsMQM0affK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}