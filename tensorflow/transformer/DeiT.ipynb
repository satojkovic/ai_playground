{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHczxJSb6Ycv"
      },
      "outputs": [],
      "source": [
        "pip install tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "tfds.disable_progress_bar()\n",
        "tf.keras.utils.set_random_seed(42)"
      ],
      "metadata": {
        "id": "tldTMHFd6cXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_TYPE = 'deit_distilled_tiny_patch16_224'\n",
        "RESOLUTION = 224\n",
        "PATCH_SIZE = 16\n",
        "NUM_PATCHES = (RESOLUTION // PATCH_SIZE) ** 2\n",
        "LAYER_NORM_EPS = 1e-6\n",
        "PROJECTION_DIM = 192\n",
        "NUM_HEADS = 3\n",
        "NUM_LAYERS = 12\n",
        "MLP_UNITS = [\n",
        "    PROJECTION_DIM * 4,\n",
        "    PROJECTION_DIM\n",
        "]\n",
        "DROPOUT_RATE = 0.0\n",
        "DROP_PATH_RATE = 0.1\n",
        "\n",
        "NUM_EPOCHS = 20\n",
        "BASE_LR = 0.0005\n",
        "WEIGHT_DECAY = 0.0001\n",
        "\n",
        "BATCH_SIZE = 256\n",
        "AUTO = tf.data.AUTOTUNE\n",
        "NUM_CLASSES = 5"
      ],
      "metadata": {
        "id": "vMZIT4rx7EAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset preparation"
      ],
      "metadata": {
        "id": "Ys9w7RnVMFCM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_dataset(is_training=True):\n",
        "  def fn(image, label):\n",
        "    if is_training:\n",
        "      # Resize to a bigger spatial resolution and take the random crops.\n",
        "      image = tf.image.resize(image, (RESOLUTION + 20, RESOLUTION + 20))\n",
        "      image = tf.image.random_crop(image, (RESOLUTION, RESOLUTION, 3))\n",
        "      image = tf.image.random_flip_left_right(image)\n",
        "    else:\n",
        "      image = tf.image.resize(image, (RESOLUTION, RESOLUTION))\n",
        "    label = tf.one_hot(label, depth=NUM_CLASSES)\n",
        "    return image, label\n",
        "\n",
        "  return fn"
      ],
      "metadata": {
        "id": "Ub2go9nE8suz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_dataset(dataset, is_training=True):\n",
        "  if is_training:\n",
        "    dataset = dataset.shuffle(BATCH_SIZE * 10)\n",
        "  dataset = dataset.map(preprocess_dataset(is_training), num_parallel_calls=AUTO)\n",
        "  return dataset.batch(BATCH_SIZE).prefetch(AUTO)"
      ],
      "metadata": {
        "id": "2jjN6EkaKKqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset, val_dataset = tfds.load(\n",
        "    \"tf_flowers\", split=['train[:90%]', 'train[90%:]'], as_supervised=True\n",
        ")\n",
        "num_train = train_dataset.cardinality()\n",
        "num_val = val_dataset.cardinality()\n",
        "print(f'num of train: {num_train}')\n",
        "print(f'num of val: {num_val}')\n",
        "\n",
        "train_dataset = prepare_dataset(train_dataset, is_training=True)\n",
        "val_dataset = prepare_dataset(val_dataset, is_training=False)"
      ],
      "metadata": {
        "id": "TALTkunXK_7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementation of DeiT"
      ],
      "metadata": {
        "id": "--2rSaGg0CBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class StochasticDepth(layers.Layer):\n",
        "  def __init__(self, drop_prop, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.drop_prop = drop_prop\n",
        "\n",
        "  def call(self, x, training=True):\n",
        "    if training:\n",
        "      keep_prob = 1- self.drop_prop\n",
        "      shape = (tf.shape(x)[0], ) + (1, ) * (len(tf.shape(x)) - 1)\n",
        "      random_tensor = keep_prob + tf.random.uniform(shape, 0, 1)\n",
        "      random_tensor = tf.floor(random_tensor)\n",
        "      return (x / keep_prob) * random_tensor\n",
        "    return x"
      ],
      "metadata": {
        "id": "M_XZOy_QLjkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mlp(x, dropout_rate, hidden_units):\n",
        "  for (idx, units) in enumerate(hidden_units):\n",
        "    x = layers.Dense(\n",
        "        units, activation=tf.nn.gelu if idx == 0 else None,\n",
        "    )(x)\n",
        "    x = layers.Dropout(dropout_rate)(x)\n",
        "  return x"
      ],
      "metadata": {
        "id": "FydwySaY03OB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transformer(drop_prob, name):\n",
        "  num_patches = NUM_PATCHES + 2 if \"distilled\" in MODEL_TYPE else NUM_PATCHES + 1\n",
        "  encoded_patches = layers.Input((num_patches, PROJECTION_DIM))\n",
        "\n",
        "  x1 = layers.LayerNormalization(epsilon=LAYER_NORM_EPS)(encoded_patches)\n",
        "  attention_output = layers.MultiHeadAttention(\n",
        "      num_heads=NUM_HEADS,\n",
        "      key_dim=PROJECTION_DIM,\n",
        "      dropout=DROPOUT_RATE\n",
        "  )(x1, x1)\n",
        "  attention_output = (\n",
        "      StochasticDepth(drop_prob)(attention_output) if drop_prob else attention_output\n",
        "  )\n",
        "\n",
        "  x2 = layers.Add()([attention_output, encoded_patches])\n",
        "  x3 = layers.LayerNormalization(epsilon=LAYER_NORM_EPS)(x2)\n",
        "  x4 = mlp(x3, dropout_rate=DROPOUT_RATE, hidden_units=MLP_UNITS)\n",
        "  x4 = StochasticDepth(drop_prop=drop_prob)(x4) if drop_prob else x4\n",
        "\n",
        "  outputs = layers.Add()([x2, x4])\n",
        "  return keras.Model(encoded_patches, outputs, name=name)\n"
      ],
      "metadata": {
        "id": "obWMDeD0QxfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ViTClassifier(keras.Model):\n",
        "  def __init__(self, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "\n",
        "    self.projection = keras.Sequential([\n",
        "        layers.Conv2D(filters=PROJECTION_DIM, kernel_size=(PATCH_SIZE, PATCH_SIZE), strides=(PATCH_SIZE, PATCH_SIZE),\n",
        "                      padding='VALID', name='conv_projection'),\n",
        "        layers.Reshape(target_shape=(NUM_PATCHES, PROJECTION_DIM), name='flatten_projection'),\n",
        "    ], name='projection')\n",
        "    \n",
        "    # Positional embedding\n",
        "    init_shape = (1, NUM_PATCHES + 1, PROJECTION_DIM)\n",
        "    self.positional_embedding = tf.Variable(tf.zeros(init_shape), name='position_embedding')\n",
        "\n",
        "    # Transformer blocks\n",
        "    dpr = [x for x in tf.linspace(0.0, DROP_PATH_RATE, NUM_LAYERS)]\n",
        "    self.transformer_blocks = [\n",
        "        transformer(drop_prob=dpr[i], name=f'transformer_block_{i}')\n",
        "        for i in range(NUM_LAYERS)\n",
        "    ]\n",
        "\n",
        "    # CLS token\n",
        "    initial_value = tf.zeros((1, 1, PROJECTION_DIM))\n",
        "    self.cls_token = tf.Variable(\n",
        "        initial_value=initial_value, trainable=True, name='cls'\n",
        "    )\n",
        "\n",
        "    # Other layers\n",
        "    self.dropout = layers.Dropout(DROPOUT_RATE)\n",
        "    self.layer_norm = layers.LayerNormalization(epsilon=LAYER_NORM_EPS)\n",
        "    self.head = layers.Dense(\n",
        "        NUM_CLASSES, name='classification_head'\n",
        "    )\n",
        "\n",
        "  def call(self, inputs, training=True):\n",
        "    n = tf.shape(inputs)[0]\n",
        "\n",
        "    projected_patches = self.projection(inputs)\n",
        "    cls_token = tf.tile(self.cls_token, (n, 1, 1))\n",
        "    cls_token = tf.cast(cls_token, projected_patches.dtype)\n",
        "    projected_patches = tf.concat([cls_token, projected_patches], axis=1)\n",
        "\n",
        "    encoded_patches = (\n",
        "        self.positional_embedding + projected_patches\n",
        "    ) # (B, number_patches, projection_dim)\n",
        "    encoded_patches = self.dropout(encoded_patches)\n",
        "\n",
        "    for transformer_module in self.transformer_blocks:\n",
        "      encoded_patches = transformer_module(encoded_patches)\n",
        "\n",
        "    representation = self.layer_norm(encoded_patches)\n",
        "    encoded_patches = representation[:, 0]\n",
        "    output = self.head(encoded_patches)\n",
        "    return output"
      ],
      "metadata": {
        "id": "C63x_WKWi66P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1GwnERSHmY1Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}