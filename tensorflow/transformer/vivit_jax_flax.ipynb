{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wab_-qZFjtMZ"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade pip\n",
        "# Installs the wheel compatible with CUDA 11 and cuDNN 8.2 or newer.\n",
        "# Note: wheels only available on linux.\n",
        "# !pip install --upgrade \"jax[cuda]\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flax\n",
        "!pip install tqdm"
      ],
      "metadata": {
        "id": "AuBBQNT3kWN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qq medmnist"
      ],
      "metadata": {
        "id": "j9hX4zqtHfOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import jax.dlpack\n",
        "from jax import grad, jit, vmap, random\n",
        "from jax import random\n",
        "from jax.example_libraries import stax, optimizers\n",
        "\n",
        "from tensorflow import keras\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "\n",
        "import time\n",
        "import numpy.random as npr\n",
        "import math\n",
        "\n",
        "from typing import Optional\n",
        "\n",
        "import optax\n",
        "from flax.training import train_state\n",
        "\n",
        "import numpy as np\n",
        "import medmnist"
      ],
      "metadata": {
        "id": "BQvUkGlFj_Qf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flax import linen as nn"
      ],
      "metadata": {
        "id": "nznZNlRZkByd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tubelet embedding"
      ],
      "metadata": {
        "id": "0YnOXRWZkLJ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TubeletEmbedding(nn.Module):\n",
        "  patch_size: int\n",
        "  embed_dim: int\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, videos):\n",
        "    patches = nn.Conv(\n",
        "        features=self.embed_dim,\n",
        "        kernel_size=[self.patch_size, self.patch_size, self.patch_size],\n",
        "        strides=[self.patch_size, self.patch_size, self.patch_size],\n",
        "        padding='VALID'\n",
        "    )(videos)\n",
        "    b, t, h, w, c = patches.shape\n",
        "    patches = jnp.reshape(patches, (b, t*h*w, c))\n",
        "    return patches"
      ],
      "metadata": {
        "id": "RoNvfPlckCz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test tubelet embedding"
      ],
      "metadata": {
        "id": "NZPvm5MtJOMk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_tubelet_embedding():\n",
        "  main_rng = jax.random.PRNGKey(42)\n",
        "  x = jnp.ones(shape=(8, 16, 32, 32, 3))\n",
        "  embedder = TubeletEmbedding(patch_size=4, embed_dim=128)\n",
        "  main_rng, rng = random.split(main_rng)\n",
        "  variables = embedder.init(main_rng, x)\n",
        "  out = embedder.apply(variables, x)\n",
        "  print(out.shape)\n",
        "  return embedder, main_rng"
      ],
      "metadata": {
        "id": "6ThXTr6qnWh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_embedder, main_rng = test_tubelet_embedding()"
      ],
      "metadata": {
        "id": "Id4E5IPDJTdo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Patch encoder"
      ],
      "metadata": {
        "id": "ewxUoqZxJ3OD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchEncoder(nn.Module):\n",
        "  hidden_dim: int\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, x):\n",
        "    assert x.ndim == 3\n",
        "    n, seq_len, _ = x.shape\n",
        "    # Hidden dim\n",
        "    x = nn.Dense(self.hidden_dim)(x)\n",
        "    # Add cls token\n",
        "    cls = self.param('cls_token', nn.initializers.zeros, (1, 1, self.hidden_dim))\n",
        "    cls = jnp.tile(cls, (n, 1, 1))\n",
        "    x = jnp.concatenate([cls, x], axis=1)\n",
        "    # Add position embedding\n",
        "    pos_embed = self.param(\n",
        "        'position_embedding',\n",
        "        nn.initializers.normal(stddev=0.02),\n",
        "        (1, seq_len + 1, self.hidden_dim)\n",
        "    )\n",
        "    return x + pos_embed"
      ],
      "metadata": {
        "id": "EYnsO7YRoCvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Spatio-temporal attention"
      ],
      "metadata": {
        "id": "dmiKA-WyqL8J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadSelfAttention(nn.Module):\n",
        "  hidden_dim: int\n",
        "  n_heads: int\n",
        "  drop_p: float\n",
        "\n",
        "  def setup(self):\n",
        "    self.q_net = nn.Dense(self.hidden_dim)\n",
        "    self.k_net = nn.Dense(self.hidden_dim)\n",
        "    self.v_net = nn.Dense(self.hidden_dim)\n",
        "\n",
        "    self.proj_net = nn.Dense(self.hidden_dim)\n",
        "\n",
        "    self.att_drop = nn.Dropout(self.drop_p)\n",
        "    self.proj_drop = nn.Dropout(self.drop_p)\n",
        "\n",
        "  def __call__(self, x, train=True):\n",
        "    B, T, C = x.shape # batch_size, seq_length, hidden_dim\n",
        "    N, D = self.n_heads, C // self.n_heads # num_heads, head_dim\n",
        "    q = self.q_net(x).reshape(B, T, N, D).transpose(0, 2, 1, 3) # (B, N, T, D)\n",
        "    k = self.k_net(x).reshape(B, T, N, D).transpose(0, 2, 1, 3)\n",
        "    v = self.v_net(x).reshape(B, T, N, D).transpose(0, 2, 1, 3)\n",
        "\n",
        "    # weights (B, N, T, T)\n",
        "    weights = jnp.matmul(q, jnp.swapaxes(k, -2, -1)) / math.sqrt(D)\n",
        "    normalized_weights = nn.softmax(weights, axis=-1)\n",
        "\n",
        "    # attention (B, N, T, D)\n",
        "    attention = jnp.matmul(normalized_weights, v)\n",
        "    attention = self.att_drop(attention, deterministic=not train)\n",
        "\n",
        "    # gather heads\n",
        "    attention = attention.transpose(0, 2, 1, 3).reshape(B, T, N*D)\n",
        "\n",
        "    # project\n",
        "    out = self.proj_drop(self.proj_net(attention), deterministic=not train)\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "VH-XasjCqQT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "  mlp_dim: int\n",
        "  drop_p: float\n",
        "  out_dim: Optional[int] = None\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, inputs, train=True):\n",
        "    actual_out_dim = inputs.shape[-1] if self.out_dim is None else self.out_dim\n",
        "    x = nn.Dense(features=self.mlp_dim)(inputs)\n",
        "    x = nn.gelu(x)\n",
        "    x = nn.Dropout(rate=self.drop_p, deterministic=not train)(x)\n",
        "    x = nn.Dense(features=actual_out_dim)(x)\n",
        "    x = nn.Dropout(rate=self.drop_p, deterministic=not train)(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "ttDUd7tTrZ1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(nn.Module):\n",
        "  embed_dim: int\n",
        "  hidden_dim: int\n",
        "  n_heads: int\n",
        "  drop_p: float\n",
        "  mlp_dim: int\n",
        "\n",
        "  def setup(self):\n",
        "    self.mha = MultiHeadSelfAttention(self.hidden_dim, self.n_heads, self.drop_p)\n",
        "    self.mlp = MLP(self.mlp_dim, self.drop_p)\n",
        "    self.layer_norm = nn.LayerNorm(epsilon=1e-6)\n",
        "  \n",
        "  def __call__(self, inputs, train=True):\n",
        "    # Attention Block\n",
        "    x = self.layer_norm(inputs)\n",
        "    x = self.mha(x, train)\n",
        "    x = inputs + x\n",
        "    # MLP block\n",
        "    y = self.layer_norm(x)\n",
        "    y = self.mlp(y, train)\n",
        "\n",
        "    return x + y"
      ],
      "metadata": {
        "id": "Q2Prvw_BrllW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ViViT(nn.Module):\n",
        "  patch_size: int\n",
        "  embed_dim: int\n",
        "  hidden_dim: int\n",
        "  n_heads: int\n",
        "  drop_p: float\n",
        "  num_layers: int\n",
        "  mlp_dim: int\n",
        "  num_classes: int\n",
        "\n",
        "  def setup(self):\n",
        "    self.patch_extracter = TubeletEmbedding(self.patch_size, self.embed_dim)\n",
        "    self.patch_encoder = PatchEncoder(self.hidden_dim)\n",
        "    self.dropout = nn.Dropout(self.drop_p)\n",
        "    self.transformer_encoder = TransformerEncoder(self.embed_dim, self.hidden_dim, self.n_heads, self.drop_p, self.mlp_dim)\n",
        "    self.cls_head = nn.Dense(features=self.num_classes)\n",
        "\n",
        "  def __call__(self, x, train=True):\n",
        "    x = self.patch_extracter(x)\n",
        "    x = self.patch_encoder(x)\n",
        "    x = self.dropout(x, deterministic=not train)\n",
        "    for i in range(self.num_layers):\n",
        "      x = self.transformer_encoder(x, train)\n",
        "    # MLP head\n",
        "    x = x[:, 0] # [CLS] token\n",
        "    x = self.cls_head(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "pql35qN3Jowp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset(medmnist)"
      ],
      "metadata": {
        "id": "VQ8F5xNrGyFX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def download_and_prepare_dataset(data_info: dict):\n",
        "    \"\"\"Utility function to download the dataset.\n",
        "\n",
        "    Arguments:\n",
        "        data_info (dict): Dataset metadata.\n",
        "    \"\"\"\n",
        "    data_path = keras.utils.get_file(origin=data_info[\"url\"], md5_hash=data_info[\"MD5\"])\n",
        "\n",
        "    with np.load(data_path) as data:\n",
        "        # Get videos\n",
        "        train_videos = data[\"train_images\"]\n",
        "        valid_videos = data[\"val_images\"]\n",
        "        test_videos = data[\"test_images\"]\n",
        "\n",
        "        # Get labels\n",
        "        train_labels = data[\"train_labels\"].flatten()\n",
        "        valid_labels = data[\"val_labels\"].flatten()\n",
        "        test_labels = data[\"test_labels\"].flatten()\n",
        "\n",
        "    return (\n",
        "        (train_videos, train_labels),\n",
        "        (valid_videos, valid_labels),\n",
        "        (test_videos, test_labels),\n",
        "    )"
      ],
      "metadata": {
        "id": "pnmFxqZVGyy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_NAME = \"organmnist3d\"\n",
        "BATCH_SIZE = 32"
      ],
      "metadata": {
        "id": "HFl4A9PiHU9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the metadata of the dataset\n",
        "info = medmnist.INFO[DATASET_NAME]\n",
        "\n",
        "# Get the dataset\n",
        "prepared_dataset = download_and_prepare_dataset(info)\n",
        "(train_videos, train_labels) = prepared_dataset[0]\n",
        "(valid_videos, valid_labels) = prepared_dataset[1]\n",
        "(test_videos, test_labels) = prepared_dataset[2]"
      ],
      "metadata": {
        "id": "NW8B9vB2HMBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'train: {len(train_videos)}, train_labels: {len(train_labels)}')\n",
        "print(f'valid: {len(valid_videos)}, valid_labels: {len(valid_labels)}')\n",
        "print(f'test: {len(test_videos)}, test_labels: {len(test_labels)}')"
      ],
      "metadata": {
        "id": "mYmlpMQhHlrg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset loader"
      ],
      "metadata": {
        "id": "f7aLlkCcGsBp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def preprocess(frames : tf.Tensor, label : tf.Tensor):\n",
        "  frames = tf.image.convert_image_dtype(\n",
        "      frames[..., tf.newaxis], tf.float32\n",
        "  )\n",
        "  label = tf.cast(label, tf.float32)\n",
        "  return frames, label"
      ],
      "metadata": {
        "id": "PkEoc8oJHwTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_dataloder(videos : np.ndarray, labels : np.ndarray, loader_type : str = \"train\", batch_size : int = BATCH_SIZE):\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((videos, labels))\n",
        "  if loader_type == \"train\":\n",
        "    dataset = dataset.shuffle(batch_size * 2)\n",
        "  \n",
        "  dataloader = (\n",
        "      dataset.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "      .batch(batch_size)\n",
        "      .prefetch(tf.data.AUTOTUNE)\n",
        "  )\n",
        "  return dataloader"
      ],
      "metadata": {
        "id": "qZB4mSUDHZIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = prepare_dataloder(train_videos, train_labels, \"train\")\n",
        "valid_loader = prepare_dataloder(valid_videos, valid_labels, \"valid\")\n",
        "test_loader = prepare_dataloder(test_videos, test_labels, \"test\")"
      ],
      "metadata": {
        "id": "lTxa7OhPH_aX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kO8KNYz2IZgh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}