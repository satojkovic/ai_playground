{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "investigate_vit",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -U gdown -q"
      ],
      "metadata": {
        "id": "oXAAI74lNFDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from dataclasses import dataclass\n",
        "import numpy as np\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import matplotlib.pyplot as plt\n",
        "import gdown\n",
        "import zipfile"
      ],
      "metadata": {
        "id": "xdI0sv9zW8MK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup configuration"
      ],
      "metadata": {
        "id": "NfQBNwSiXmFp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RESOLUTION = 224\n",
        "PATCH_SIZE = 16"
      ],
      "metadata": {
        "id": "5QSM3iONXlpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data augmentation & preprocessing\n",
        "\n"
      ],
      "metadata": {
        "id": "yd2wJoyUWiBs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LutucbozWd9T"
      },
      "outputs": [],
      "source": [
        "crop_layer = layers.CenterCrop(RESOLUTION, RESOLUTION)\n",
        "norm_layer = layers.Normalization(\n",
        "    mean=[0.485 * 255, 0.456 * 255, 0.406 * 255],\n",
        "    variance=[(0.229 * 255) ** 2, (0.224 * 255) ** 2, (0.225 * 255) ** 2],\n",
        ")\n",
        "rescale_layer = layers.Rescaling(scale=1.0/127.5, offset=-1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(image, model_type, size=RESOLUTION):\n",
        "  image = np.array(image)\n",
        "  image = tf.expand_dims(image, 0)\n",
        "\n",
        "  # If the `model_type` is ViT, rescale the image to [-1, 1]\n",
        "  if model_type == 'original_vit':\n",
        "    image = rescale_layer(image)\n",
        "\n",
        "  resize_size = int((256 / 224) * size)\n",
        "  image = tf.image.resize(image, (resize_size, resize_size), method='bicubic')\n",
        "\n",
        "  image = crop_layer(image)\n",
        "\n",
        "  # If the `model_type` is Deit or DINO, normalize the image\n",
        "  if model_type != 'original_vit':\n",
        "    image = norm_layer(image)\n",
        "\n",
        "  return image.numpy()"
      ],
      "metadata": {
        "id": "UzkyuGWdP-rg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load a test image and display it"
      ],
      "metadata": {
        "id": "yqQb01PURFry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image_from_url(url, model_type):\n",
        "  response = requests.get(url)\n",
        "  image = Image.open(BytesIO(response.content))\n",
        "  preprocessed_image = preprocess_image(image, model_type)\n",
        "  return image, preprocessed_image"
      ],
      "metadata": {
        "id": "aJTId7UjRFL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mapping_file = keras.utils.get_file(\n",
        "  origin=\"https://storage.googleapis.com/bit_models/ilsvrc2012_wordnet_lemmas.txt\"\n",
        ")"
      ],
      "metadata": {
        "id": "GnYkf9VGQ99S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(mapping_file, 'r') as f:\n",
        "  lines = f.readlines()\n",
        "imagenet_int_to_str = [line.rstrip() for line in lines]"
      ],
      "metadata": {
        "id": "O36VRPKRR4DV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_url = \"https://dl.fbaipublicfiles.com/dino/img.png\"\n",
        "image, preprocessed_image = load_image_from_url(img_url, model_type=\"original_vit\")\n",
        "\n",
        "plt.imshow(image)\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_2O3XDVaSCr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load a model\n",
        "\n",
        "This model was pretrained on the ImageNet-21k dataset and was then fine-tuned on the ImageNet-1k dataset"
      ],
      "metadata": {
        "id": "-6AKtP1_mI_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_gdrive_model(model_id):\n",
        "  model_path = gdown.download(id=model_id, quiet=False)\n",
        "  with zipfile.ZipFile(model_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall()\n",
        "  model_name = model_path.split('.')[0]\n",
        "  inputs = keras.Input((RESOLUTION, RESOLUTION, 3))\n",
        "  model = keras.models.load_model(model_name, compile=False)\n",
        "  outputs, attention_weights = model(inputs)\n",
        "  return keras.Model(inputs, outputs=[outputs, attention_weights])"
      ],
      "metadata": {
        "id": "7HjLxguimIpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vit_base_i21k_patch16_224 = get_gdrive_model(\"1mbtnliT3jRb3yJUHhbItWw8unfYZw8KJ\")\n",
        "print(\"Model loaded.\")"
      ],
      "metadata": {
        "id": "aVH3CCQLSFs7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ],
      "metadata": {
        "id": "jY7z2QwBn-o-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions, attention_score_dict = vit_base_i21k_patch16_224.predict(preprocessed_image)"
      ],
      "metadata": {
        "id": "MCesJRA0n-W_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_label = imagenet_int_to_str[int(np.argmax(predictions))]"
      ],
      "metadata": {
        "id": "U9MX2hvFnX5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(predicted_label)"
      ],
      "metadata": {
        "id": "ymEK9SKwoRys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "iqjSb60doTr8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}