{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras_swin_transformer",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLjIxerdnqfH"
      },
      "outputs": [],
      "source": [
        "!pip install -U tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "upnw3_BQnuR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preparation"
      ],
      "metadata": {
        "id": "Jrz2WcZSoF_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLASSES = 100\n",
        "INPUT_SHAPE = (32, 32, 3)\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar100.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "y_train = keras.utils.to_categorical(y_train, NUM_CLASSES)\n",
        "y_test = keras.utils.to_categorical(y_test, NUM_CLASSES)\n",
        "print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n",
        "print(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5, 5, i + 1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(x_train[i])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OJ7yNzmhn9Cc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyper-parameters"
      ],
      "metadata": {
        "id": "EK4IHKv1mNKh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATCH_SIZE = (2, 2)  # 2-by-2 sized patches\n",
        "DROPOUT_RATE = 0.03  # Dropout rate\n",
        "num_heads = 8  # Attention heads\n",
        "EMBED_DIM = 64  # Embedding dimension\n",
        "num_mlp = 256  # MLP layer size\n",
        "qkv_bias = True  # Convert embedded patches to query, key, and values with a learnable additive value\n",
        "WINDOW_SIZE = 2 # Size of attention window\n",
        "SHIFT_SIZE = 1  # Size of shifting window\n",
        "IMAGE_DIMENSION = 32  # Initial image size\n",
        "\n",
        "NUM_PATCH_X = INPUT_SHAPE[0] // PATCH_SIZE[0]\n",
        "NUM_PATCH_Y = INPUT_SHAPE[1] // PATCH_SIZE[1]\n",
        "\n",
        "learning_rate = 1e-3\n",
        "batch_size = 128\n",
        "num_epochs = 40\n",
        "validation_split = 0.1\n",
        "weight_decay = 0.0001\n",
        "label_smoothing = 0.1"
      ],
      "metadata": {
        "id": "G7i8639coBJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Window partition"
      ],
      "metadata": {
        "id": "f--d5MhYocQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def window_partition(x, window_size):\n",
        "  _, height, width, channels = x.shape\n",
        "  patch_num_y = height // window_size\n",
        "  patch_num_x = width // window_size \n",
        "  # `batch_size` remains same\n",
        "  # `height` and `width` are factorized into `patch_num` * `window_size`\n",
        "  x = tf.reshape(\n",
        "      x, shape=[-1, patch_num_y, window_size, patch_num_x, window_size, channels]\n",
        "  )\n",
        "  # patch_index first\n",
        "  x = tf.transpose(x, [0, 1, 3, 2, 4, 5])\n",
        "  # window index based array\n",
        "  windows = tf.reshape(x, shape=[-1, window_size, window_size, channels])\n",
        "  return windows"
      ],
      "metadata": {
        "id": "0pkyt8Ghod4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def window_reverse(windows, window_size, height, width, channels):\n",
        "    patch_num_y = height // window_size\n",
        "    patch_num_x = width // window_size\n",
        "    x = tf.reshape(\n",
        "        windows,\n",
        "        shape=(-1, patch_num_y, patch_num_x, window_size, window_size, channels),\n",
        "    )\n",
        "    x = tf.transpose(x, perm=(0, 1, 3, 2, 4, 5))\n",
        "    x = tf.reshape(x, shape=(-1, height, width, channels))\n",
        "    return x"
      ],
      "metadata": {
        "id": "pj07jlRIAqSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DropPath(layers.Layer):\n",
        "  def __init__(self, drop_prob=None, **kwargs):\n",
        "    super(DropPath, self).__init__(**kwargs)\n",
        "    self.drop_prob = drop_prob\n",
        "\n",
        "  def call(self, x):\n",
        "    input_shape = tf.shape(x)\n",
        "    batch_size = input_shape[0]\n",
        "    rank = x.shape.rank\n",
        "    shape = (batch_size,) + (1,) * (rank - 1)\n",
        "    random_tensor = (1 - self.drop_prob) + tf.random.uniform(shape, dtype=x.dtype)\n",
        "    path_mask = tf.floor(random_tensor)\n",
        "    output = tf.math.divide(x, 1 - self.drop_prob) * path_mask\n",
        "    return output"
      ],
      "metadata": {
        "id": "Kg7dsCzIEHBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Swin Transformer"
      ],
      "metadata": {
        "id": "qUCTjW5sEaSN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchExtract(layers.Layer):\n",
        "  def __init__(self, patch_size, **kwargs):\n",
        "    super(PatchExtract, self).__init__(**kwargs)\n",
        "    self.patch_size_x = patch_size[0]\n",
        "    self.patch_size_y = patch_size[1]\n",
        "\n",
        "  def call(self, images):\n",
        "    batch_size = tf.shape(images)[0]\n",
        "    patches = tf.image.extract_patches(\n",
        "        images=images,\n",
        "        sizes=(1, self.patch_size_y, self.patch_size_x, 1),\n",
        "        strides=(1, self.patch_size_y, self.patch_size_x, 1), # non-overlapping\n",
        "        rates=(1, 1, 1, 1), # no subsample\n",
        "        padding='VALID'\n",
        "    )\n",
        "    patch_dim = patches.shape[-1] # patch_size_y * patch_size_x\n",
        "    patch_num = patches.shape[1]\n",
        "    return tf.reshape(patches, (batch_size, patch_num * patch_num, patch_dim))\n"
      ],
      "metadata": {
        "id": "0H4GbMqhHkTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchEmbedding(layers.Layer):\n",
        "  def __init__(self, num_patch, embed_dim, **kwargs):\n",
        "    super(PatchEmbedding, self).__init__(**kwargs)\n",
        "    self.num_patch = num_patch\n",
        "    self.proj = layers.Dense(embed_dim)\n",
        "    self.pos_embed = layers.Embedding(input_dim=num_patch, output_dim=embed_dim)\n",
        "\n",
        "  def call(self, patch):\n",
        "    pos = tf.range(start=0, limit=self.num_patch, delta=1)\n",
        "    return self.proj(patch) + self.pos_embed(pos)"
      ],
      "metadata": {
        "id": "DtUMCHHYLlyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchMerging(layers.Layer):\n",
        "  def __init__(self, num_patch, embed_dim):\n",
        "    super(PatchMerging, self).__init__()\n",
        "    self.num_patch = num_patch\n",
        "    self.embed_dim = embed_dim\n",
        "    self.linear_trans = layers.Dense(2 * embed_dim, use_bias=False)\n",
        "\n",
        "  def call(self, x):\n",
        "    height, width = self.num_patch\n",
        "    _, _, C = x.get_shape().as_list()\n",
        "    x = tf.reshape(x, shape=(-1, height, width, C))\n",
        "    x0 = x[:, 0::2, 0::2, :]\n",
        "    x1 = x[:, 1::2, 0::2, :]\n",
        "    x2 = x[:, 0::2, 1::2, :]\n",
        "    x3 = x[:, 1::2, 1::2, :]\n",
        "    x = tf.concat((x0, x1, x2, x3), axis=-1)\n",
        "    x = tf.reshape(x, shape=(-1, (height // 2) * (width // 2), 4 * C))\n",
        "    return self.linear_trans(x)"
      ],
      "metadata": {
        "id": "kCwAgkq2cf5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Window based multi head self attention"
      ],
      "metadata": {
        "id": "-VOq5PPzSwd_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class WindowAttention(layers.Layer):\n",
        "  def __init__(\n",
        "      self, dim, window_size, num_heads, qkv_bias=True, dropout_rate=0.0, **kwargs\n",
        "  ):\n",
        "    super(WindowAttention, self).__init__(**kwargs)\n",
        "    self.dim = dim\n",
        "    self.window_size = window_size\n",
        "    self.num_heads = num_heads\n",
        "    self.scale = (dim // num_heads) ** -0.5\n",
        "    self.qkv = layers.Dense(dim * 3, use_bias=qkv_bias)\n",
        "    self.dropout = layers.Dropout(dropout_rate)\n",
        "    self.proj = layers.Dense(dim)\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    num_window_elements = (2 * self.window_size[0] - 1) * (\n",
        "        2 * self.window_size[1] - 1\n",
        "    )\n",
        "    self.relative_position_bias_table = self.add_weight(\n",
        "        shape=(num_window_elements, self.num_heads),\n",
        "        initializer=tf.initializers.Zeros(),\n",
        "        trainable=True,\n",
        "    )\n",
        "    coords_h = np.arange(self.window_size[0])\n",
        "    coords_w = np.arange(self.window_size[1])\n",
        "    coords_matrix = np.meshgrid(coords_h, coords_w, indexing=\"ij\")\n",
        "    coords = np.stack(coords_matrix)\n",
        "    coords_flatten = coords.reshape(2, -1)\n",
        "    relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]\n",
        "    relative_coords = relative_coords.transpose([1, 2, 0])\n",
        "    relative_coords[:, :, 0] += self.window_size[0] - 1\n",
        "    relative_coords[:, :, 1] += self.window_size[1] - 1\n",
        "    relative_coords[:, :, 0] *= 2 * self.window_size[1] - 1\n",
        "    relative_position_index = relative_coords.sum(-1)\n",
        "\n",
        "    self.relative_position_index = tf.Variable(\n",
        "        initial_value=tf.convert_to_tensor(relative_position_index), trainable=False\n",
        "    )\n",
        "\n",
        "  def call(self, x, mask=None):\n",
        "    _, size, channels = x.shape\n",
        "    head_dim = channels // self.num_heads\n",
        "    x_qkv = self.qkv(x)\n",
        "    x_qkv = tf.reshape(x_qkv, shape=(-1, size, 3, self.num_heads, head_dim))\n",
        "    x_qkv = tf.transpose(x_qkv, perm=(2, 0, 3, 1, 4))\n",
        "    q, k, v = x_qkv[0], x_qkv[1], x_qkv[2]\n",
        "    q = q * self.scale\n",
        "    k = tf.transpose(k, perm=(0, 1, 3, 2))\n",
        "    attn = q @ k\n",
        "\n",
        "    num_window_elements = self.window_size[0] * self.window_size[1]\n",
        "    relative_position_index_flat = tf.reshape(\n",
        "        self.relative_position_index, shape=(-1,)\n",
        "    )\n",
        "    relative_position_bias = tf.gather(\n",
        "        self.relative_position_bias_table, relative_position_index_flat\n",
        "    )\n",
        "    relative_position_bias = tf.reshape(\n",
        "        relative_position_bias, shape=(num_window_elements, num_window_elements, -1)\n",
        "    )\n",
        "    relative_position_bias = tf.transpose(relative_position_bias, perm=(2, 0, 1))\n",
        "    attn = attn + tf.expand_dims(relative_position_bias, axis=0)\n",
        "\n",
        "    if mask is not None:\n",
        "        nW = mask.get_shape()[0]\n",
        "        mask_float = tf.cast(\n",
        "            tf.expand_dims(tf.expand_dims(mask, axis=1), axis=0), tf.float32\n",
        "        )\n",
        "        attn = (\n",
        "            tf.reshape(attn, shape=(-1, nW, self.num_heads, size, size))\n",
        "            + mask_float\n",
        "        )\n",
        "        attn = tf.reshape(attn, shape=(-1, self.num_heads, size, size))\n",
        "        attn = keras.activations.softmax(attn, axis=-1)\n",
        "    else:\n",
        "        attn = keras.activations.softmax(attn, axis=-1)\n",
        "    attn = self.dropout(attn)\n",
        "\n",
        "    x_qkv = attn @ v\n",
        "    x_qkv = tf.transpose(x_qkv, perm=(0, 2, 1, 3))\n",
        "    x_qkv = tf.reshape(x_qkv, shape=(-1, size, channels))\n",
        "    x_qkv = self.proj(x_qkv)\n",
        "    x_qkv = self.dropout(x_qkv)\n",
        "    return x_qkv    "
      ],
      "metadata": {
        "id": "8bW959U7fIE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SwinTransformer(layers.Layer):\n",
        "  def __init__(\n",
        "      self,\n",
        "      dim,\n",
        "      num_patch,\n",
        "      num_heads,\n",
        "      window_size=7,\n",
        "      shift_size=0,\n",
        "      num_mlp=1024,\n",
        "      qkv_bias=True,\n",
        "      dropout_rate=0.0,\n",
        "      **kwargs\n",
        "  ):\n",
        "    super(SwinTransformer, self).__init__(**kwargs)\n",
        "    self.dim = dim\n",
        "    self.num_patch = num_patch\n",
        "    self.num_heads = num_heads\n",
        "    self.window_size = window_size\n",
        "    self.shift_size = shift_size\n",
        "    self.num_mlp = num_mlp\n",
        "    self.qkv_bias = qkv_bias\n",
        "    self.dropout_rate = dropout_rate\n",
        "\n",
        "    self.norm1 = layers.LayerNormalization(epsilon=1e-5)\n",
        "    self.attn = WindowAttention(\n",
        "        dim, window_size=(self.window_size, self.window_size),\n",
        "        num_heads=num_heads, qkv_bias=qkv_bias, dropout_rate=self.dropout_rate\n",
        "    )\n",
        "    self.drop_path = DropPath(self.dropout_rate)\n",
        "    self.norm2 = layers.LayerNormalization(epsilon=1e-5)\n",
        "\n",
        "    self.mlp = keras.Sequential([\n",
        "        layers.Dense(num_mlp),\n",
        "        layers.Activation(keras.activations.gelu),\n",
        "        layers.Dropout(dropout_rate),\n",
        "        layers.Dense(dim),\n",
        "        layers.Dropout(dropout_rate)\n",
        "    ])\n",
        "\n",
        "    if min(self.num_patch) < self.window_size: # num_patch=(num_patch_x, num_patch_y)\n",
        "      self.shift_size = 0\n",
        "      self.window_size = min(self.num_patch)\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    if self.shift_size == 0:\n",
        "        self.attn_mask = None\n",
        "    else:\n",
        "        height, width = self.num_patch\n",
        "        h_slices = (\n",
        "            slice(0, -self.window_size),\n",
        "            slice(-self.window_size, -self.shift_size),\n",
        "            slice(-self.shift_size, None),\n",
        "        )\n",
        "        w_slices = (\n",
        "            slice(0, -self.window_size),\n",
        "            slice(-self.window_size, -self.shift_size),\n",
        "            slice(-self.shift_size, None),\n",
        "        )\n",
        "        mask_array = np.zeros((1, height, width, 1))\n",
        "        count = 0\n",
        "        for h in h_slices:\n",
        "            for w in w_slices:\n",
        "                mask_array[:, h, w, :] = count\n",
        "                count += 1\n",
        "        mask_array = tf.convert_to_tensor(mask_array)\n",
        "\n",
        "        # mask array to windows\n",
        "        mask_windows = window_partition(mask_array, self.window_size)\n",
        "        mask_windows = tf.reshape(\n",
        "            mask_windows, shape=[-1, self.window_size * self.window_size]\n",
        "        )\n",
        "        attn_mask = tf.expand_dims(mask_windows, axis=1) - tf.expand_dims(\n",
        "            mask_windows, axis=2\n",
        "        )\n",
        "        attn_mask = tf.where(attn_mask != 0, -100.0, attn_mask)\n",
        "        attn_mask = tf.where(attn_mask == 0, 0.0, attn_mask)\n",
        "        self.attn_mask = tf.Variable(initial_value=attn_mask, trainable=False)\n",
        "\n",
        "  def call(self, x):\n",
        "    height, width = self.num_patch\n",
        "    _, num_patches_before, channels = x.shape\n",
        "    x_skip = x\n",
        "    x = self.norm1(x)\n",
        "    x = tf.reshape(x, shape=(-1, height, width, channels))\n",
        "    if self.shift_size > 0:\n",
        "        shifted_x = tf.roll(\n",
        "            x, shift=[-self.shift_size, -self.shift_size], axis=[1, 2]\n",
        "        )\n",
        "    else:\n",
        "        shifted_x = x\n",
        "\n",
        "    x_windows = window_partition(shifted_x, self.window_size)\n",
        "    print(f'x_windows: {x_windows.shape}')\n",
        "    x_windows = tf.reshape(\n",
        "        x_windows, shape=(-1, self.window_size * self.window_size, channels)\n",
        "    )\n",
        "    print(f'x_windows reshaped: {x_windows.shape}')\n",
        "    attn_windows = self.attn(x_windows, mask=self.attn_mask)\n",
        "    print(f'attn_windows: {attn_windows.shape}')\n",
        "    attn_windows = tf.reshape(\n",
        "        attn_windows, shape=(-1, self.window_size, self.window_size, channels)\n",
        "    )\n",
        "    print(f'attn_windows reshaped: {attn_windows.shape}')\n",
        "    shifted_x = window_reverse(\n",
        "        attn_windows, self.window_size, height, width, channels\n",
        "    )\n",
        "    if self.shift_size > 0:\n",
        "        x = tf.roll(\n",
        "            shifted_x, shift=[self.shift_size, self.shift_size], axis=[1, 2]\n",
        "        )\n",
        "    else:\n",
        "        x = shifted_x\n",
        "\n",
        "    x = tf.reshape(x, shape=(-1, height * width, channels))\n",
        "    x = self.drop_path(x)\n",
        "    x = x_skip + x\n",
        "    x_skip = x\n",
        "    x = self.norm2(x)\n",
        "    x = self.mlp(x)\n",
        "    x = self.drop_path(x)\n",
        "    x = x_skip + x\n",
        "    return x"
      ],
      "metadata": {
        "id": "-lkAhgd-atH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_swin_transformer(\n",
        "    input_shape=INPUT_SHAPE,\n",
        "    image_dimension=IMAGE_DIMENSION,\n",
        "    patch_size=PATCH_SIZE,\n",
        "    num_patch_x=NUM_PATCH_X,\n",
        "    num_patch_y=NUM_PATCH_Y,\n",
        "    embed_dim=EMBED_DIM,\n",
        "    num_classes=NUM_CLASSES,\n",
        "    shift_size=SHIFT_SIZE,\n",
        "    window_size=WINDOW_SIZE,\n",
        "    dropout_rate=DROPOUT_RATE,\n",
        "):\n",
        "  # Print args\n",
        "  print(f'input_shape: {input_shape}')\n",
        "  print(f'num_patch_x: {num_patch_x}')\n",
        "  print(f'num_patch_y: {num_patch_y}')\n",
        "  print(f'image_dimension: {image_dimension}')\n",
        "\n",
        "  inputs = layers.Input(shape=input_shape) # (32, 32, 3)\n",
        "  x = layers.RandomCrop(image_dimension, image_dimension)(inputs) # crop image from the input randomly\n",
        "  x = layers.RandomFlip('horizontal')(x)\n",
        "  x = PatchExtract(patch_size)(x)\n",
        "  print(f'patch extract: {x.shape}')\n",
        "  x = PatchEmbedding(num_patch_x * num_patch_y, embed_dim)(x)\n",
        "  print(f'patch embedding: {x.shape}')\n",
        "\n",
        "  #\n",
        "  # Swin Transformer Block\n",
        "  #\n",
        "  x = SwinTransformer(\n",
        "      dim=embed_dim,\n",
        "      num_patch=(num_patch_y, num_patch_x),\n",
        "      num_heads=num_heads,\n",
        "      window_size=window_size,\n",
        "      shift_size=shift_size,\n",
        "      num_mlp=num_mlp,\n",
        "      qkv_bias=qkv_bias,\n",
        "      dropout_rate=dropout_rate\n",
        "  )(x)\n",
        "  print(f'swin_transformer 1: {x.shape}')\n",
        "\n",
        "  x = SwinTransformer(\n",
        "      dim=embed_dim,\n",
        "      num_patch=(num_patch_y, num_patch_x),\n",
        "      num_heads=num_heads,\n",
        "      window_size=window_size,\n",
        "      shift_size=shift_size,\n",
        "      num_mlp=num_mlp,\n",
        "      qkv_bias=qkv_bias,\n",
        "      dropout_rate=dropout_rate\n",
        "  )(x)\n",
        "  print(f'swin_transformer 2: {x.shape}')\n",
        "\n",
        "  # Patch Merging\n",
        "  x = PatchMerging((num_patch_y, num_patch_x), embed_dim)(x)\n",
        "  print(f'patch merging: {x.shape}')\n",
        "\n",
        "  # Classification Head\n",
        "  x = layers.GlobalAveragePooling1D()(x) # (batch_size, embed_dim)\n",
        "  print(f'global avg pool1d: {x.shape}')\n",
        "  outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "  print(f'outputs: {outputs.shape}')\n",
        "\n",
        "  # Create model\n",
        "  model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "  return model"
      ],
      "metadata": {
        "id": "h4_coLZhEcBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_swin_transformer()"
      ],
      "metadata": {
        "id": "uHY879g-MhIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SB5kXR_NIkwz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}