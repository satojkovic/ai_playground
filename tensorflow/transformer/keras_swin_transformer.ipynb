{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras_swin_transformer",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLjIxerdnqfH"
      },
      "outputs": [],
      "source": [
        "!pip install -U tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "upnw3_BQnuR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preparation"
      ],
      "metadata": {
        "id": "Jrz2WcZSoF_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLASSES = 100\n",
        "INPUT_SHAPE = (32, 32, 3)\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar100.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "y_train = keras.utils.to_categorical(y_train, NUM_CLASSES)\n",
        "y_test = keras.utils.to_categorical(y_test, NUM_CLASSES)\n",
        "print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n",
        "print(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5, 5, i + 1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(x_train[i])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OJ7yNzmhn9Cc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyper-parameters"
      ],
      "metadata": {
        "id": "EK4IHKv1mNKh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATCH_SIZE = (2, 2)  # 2-by-2 sized patches\n",
        "dropout_rate = 0.03  # Dropout rate\n",
        "num_heads = 8  # Attention heads\n",
        "EMBED_DIM = 64  # Embedding dimension\n",
        "num_mlp = 256  # MLP layer size\n",
        "qkv_bias = True  # Convert embedded patches to query, key, and values with a learnable additive value\n",
        "WINDOW_SIZE = 2 # Size of attention window\n",
        "SHIFT_SIZE = 1  # Size of shifting window\n",
        "IMAGE_DIMENSION = 32  # Initial image size\n",
        "\n",
        "NUM_PATCH_X = INPUT_SHAPE[0] // PATCH_SIZE[0]\n",
        "NUM_PATCH_Y = INPUT_SHAPE[1] // PATCH_SIZE[1]\n",
        "\n",
        "learning_rate = 1e-3\n",
        "batch_size = 128\n",
        "num_epochs = 40\n",
        "validation_split = 0.1\n",
        "weight_decay = 0.0001\n",
        "label_smoothing = 0.1"
      ],
      "metadata": {
        "id": "G7i8639coBJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Window partition"
      ],
      "metadata": {
        "id": "f--d5MhYocQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def window_partition(x, window_size):\n",
        "  _, height, width, channels = x.shape\n",
        "  print(f'height: {height}, width: {width}, channels: {channels} @ window_partition')\n",
        "  patch_num_y = height // window_size\n",
        "  patch_num_x = width // window_size \n",
        "  print(f'patch_num_y: {patch_num_y}, patch_num_x: {patch_num_x} @ window_partition')\n",
        "  # `batch_size` remains same\n",
        "  # `height` and `width` are factorized into `patch_num` * `window_size`\n",
        "  x = tf.reshape(\n",
        "      x, shape=[-1, patch_num_y, window_size, patch_num_x, window_size, channels]\n",
        "  )\n",
        "  print(f'x_reshaped: {x.shape} @ window_partition')\n",
        "  # patch_index first\n",
        "  x = tf.transpose(x, [0, 1, 3, 2, 4, 5])\n",
        "  print(f'x_transposed[0, 1, 3, 2, 4, 5]: {x.shape} @ window_partition')\n",
        "  # window index based array\n",
        "  windows = tf.reshape(x, shape=[-1, window_size, window_size, channels])\n",
        "  return windows"
      ],
      "metadata": {
        "id": "0pkyt8Ghod4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def window_reverse(windows, window_size, height, width, channels):\n",
        "    patch_num_y = height // window_size\n",
        "    patch_num_x = width // window_size\n",
        "    x = tf.reshape(\n",
        "        windows,\n",
        "        shape=(-1, patch_num_y, patch_num_x, window_size, window_size, channels),\n",
        "    )\n",
        "    x = tf.transpose(x, perm=(0, 1, 3, 2, 4, 5))\n",
        "    x = tf.reshape(x, shape=(-1, height, width, channels))\n",
        "    return x"
      ],
      "metadata": {
        "id": "pj07jlRIAqSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DropPath(layers.Layer):\n",
        "    def __init__(self, drop_prob=None, **kwargs):\n",
        "        super(DropPath, self).__init__(**kwargs)\n",
        "        self.drop_prob = drop_prob\n",
        "\n",
        "    def call(self, x):\n",
        "        input_shape = tf.shape(x)\n",
        "        batch_size = input_shape[0]\n",
        "        rank = x.shape.rank\n",
        "        shape = (batch_size,) + (1,) * (rank - 1)\n",
        "        random_tensor = (1 - self.drop_prob) + tf.random.uniform(shape, dtype=x.dtype)\n",
        "        path_mask = tf.floor(random_tensor)\n",
        "        output = tf.math.divide(x, 1 - self.drop_prob) * path_mask\n",
        "        return output"
      ],
      "metadata": {
        "id": "Kg7dsCzIEHBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Swin Transformer"
      ],
      "metadata": {
        "id": "qUCTjW5sEaSN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchExtract(layers.Layer):\n",
        "  def __init__(self, patch_size, **kwargs):\n",
        "    super(PatchExtract, self).__init__(**kwargs)\n",
        "    self.patch_size_x = patch_size[0]\n",
        "    self.patch_size_y = patch_size[1]\n",
        "\n",
        "  def call(self, images):\n",
        "    batch_size = tf.shape(images)[0]\n",
        "    patches = tf.image.extract_patches(\n",
        "        images=images,\n",
        "        sizes=(1, self.patch_size_y, self.patch_size_x, 1),\n",
        "        strides=(1, self.patch_size_y, self.patch_size_x, 1), # non-overlapping\n",
        "        rates=(1, 1, 1, 1), # no subsample\n",
        "        padding='VALID'\n",
        "    )\n",
        "    patch_dim = patches.shape[-1] # patch_size_y * patch_size_x\n",
        "    patch_num = patches.shape[1]\n",
        "    return tf.reshape(patches, (batch_size, patch_num * patch_num, patch_dim))\n"
      ],
      "metadata": {
        "id": "0H4GbMqhHkTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchEmbedding(layers.Layer):\n",
        "  def __init__(self, num_patch, embed_dim, **kwargs):\n",
        "    super(PatchEmbedding, self).__init__(**kwargs)\n",
        "    self.num_patch = num_patch\n",
        "    self.proj = layers.Dense(embed_dim)\n",
        "    self.pos_embed = layers.Embedding(input_dim=num_patch, output_dim=embed_dim)\n",
        "\n",
        "  def call(self, patch):\n",
        "    pos = tf.range(start=0, limit=self.num_patch, delta=1)\n",
        "    return self.proj(patch) + self.pos_embed(pos)"
      ],
      "metadata": {
        "id": "DtUMCHHYLlyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_swin_transformer(\n",
        "    input_shape=INPUT_SHAPE,\n",
        "    image_dimension=IMAGE_DIMENSION,\n",
        "    patch_size=PATCH_SIZE,\n",
        "    num_patch_x=NUM_PATCH_X,\n",
        "    num_patch_y=NUM_PATCH_Y,\n",
        "    embed_dim=EMBED_DIM,\n",
        "    num_classes=NUM_CLASSES,\n",
        "    shift_size=SHIFT_SIZE,\n",
        "    window_size=WINDOW_SIZE,\n",
        "):\n",
        "  # Print args\n",
        "  print(f'input_shape: {input_shape}')\n",
        "  print(f'num_patch_x: {num_patch_x}')\n",
        "  print(f'num_patch_y: {num_patch_y}')\n",
        "  print(f'image_dimension: {image_dimension}')\n",
        "\n",
        "  inputs = layers.Input(shape=input_shape) # (32, 32, 3)\n",
        "  x = layers.RandomCrop(image_dimension, image_dimension)(inputs) # crop image from the input randomly\n",
        "  x = layers.RandomFlip('horizontal')(x)\n",
        "  x = PatchExtract(patch_size)(x)\n",
        "  print(f'patch extract: {x.shape}')\n",
        "  x = PatchEmbedding(num_patch_x * num_patch_y, embed_dim)(x)\n",
        "  print(f'patch embedding: {x.shape}')\n",
        "\n",
        "  #\n",
        "  # Swin Transformer Block\n",
        "  #\n",
        "\n",
        "  # skip connection and LN\n",
        "  height, width = num_patch_y, num_patch_x\n",
        "  _, num_patches_before, channels = x.shape\n",
        "  x_skip = x\n",
        "  x = layers.LayerNormalization(epsilon=1e-5)(x)\n",
        "  print(f'LN: {x.shape}')\n",
        "\n",
        "  # patch extract from shifted window\n",
        "  x = tf.reshape(x, shape=(-1, height, width, channels))\n",
        "  print(f'x_reshaped: {x.shape}')\n",
        "  if shift_size > 0:\n",
        "    shifted_x = tf.roll(x, shift=[-shift_size, -shift_size], axis=[1, 2]) # shift backward for each axis\n",
        "  else:\n",
        "    shifted_x = x\n",
        "  print(f'shifted_x: {shifted_x.shape}')\n",
        "  x_windows = window_partition(shifted_x, window_size)\n",
        "  print(f'x_windows: {x_windows.shape}') # 4 windows\n",
        "\n",
        "  x = tf.reshape(x, shape=(-1, height * width, embed_dim)) # temporal\n",
        "\n",
        "  # Classification Head\n",
        "  x = layers.GlobalAveragePooling1D()(x) # (batch_size, embed_dim)\n",
        "  print(f'global avg pool1d: {x.shape}')\n",
        "  outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "  print(f'outputs: {outputs.shape}')\n",
        "\n",
        "  # Create model\n",
        "  model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "  return model"
      ],
      "metadata": {
        "id": "h4_coLZhEcBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_swin_transformer()"
      ],
      "metadata": {
        "id": "uHY879g-MhIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SB5kXR_NIkwz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}