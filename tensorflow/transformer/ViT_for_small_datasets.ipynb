{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ViT_for_small_datasets",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pf5wzoVhVCnp"
      },
      "outputs": [],
      "source": [
        "pip install -qq -U tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "gazpwBl-VYoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLASSES = 100\n",
        "INPUT_SHAPE = (32, 32, 3)\n",
        "\n",
        "IMAGE_SIZE = 72\n",
        "PATCH_SIZE = 6\n",
        "NUM_PATCHES = (IMAGE_SIZE // PATCH_SIZE) ** 2\n",
        "\n",
        "PROJECTION_DIM = 64"
      ],
      "metadata": {
        "id": "0bJyDGF3VLdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar100.load_data()"
      ],
      "metadata": {
        "id": "jPlk9I3tVTPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data augmentation\n",
        "\n",
        "According to DeiT, various techniqus are required to effectively train ViTs.\n",
        "Thus we applied data augmentations such as CutMix, Mixup, Auto Augment, Repeated Augment to all models."
      ],
      "metadata": {
        "id": "JOx0EPrBV3TK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = tf.keras.Sequential(\n",
        "  [\n",
        "    tf.keras.layers.Normalization(),\n",
        "    tf.keras.layers.Resizing(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    tf.keras.layers.RandomFlip('horizontal'),\n",
        "    tf.keras.layers.RandomRotation(factor=0.2),\n",
        "    tf.keras.layers.RandomZoom(height_factor=0.2, width_factor=0.2),\n",
        "  ],\n",
        "  name='data_augmentation'\n",
        ")\n",
        "# Compute the mean and the variance of the training data for normalization.\n",
        "data_augmentation.layers[0].adapt(x_train)"
      ],
      "metadata": {
        "id": "TU2CyKiwV25m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PatchEncoder"
      ],
      "metadata": {
        "id": "b6MGDuqXjFlw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchEncoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_patches=NUM_PATCHES, projection_dim=PROJECTION_DIM, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.num_patches = num_patches\n",
        "    self.position_embedding = tf.keras.layers.Embedding(\n",
        "        input_dim=num_patches, output_dim=projection_dim\n",
        "    )\n",
        "    self.positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
        "\n",
        "  def call(self, encoded_patches):\n",
        "    encoded_positions = self.position_embedding(self.positions)\n",
        "    encoded_patches = encoded_patches + encoded_positions\n",
        "    return encoded_patches"
      ],
      "metadata": {
        "id": "CdLzP_w6VeF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Shifted patch tokenization\n",
        "\n",
        "* start with an image\n",
        "* shift the image in diagonal direction\n",
        "* concat the diagonally shifted images with the orignal image\n",
        "* extract pathces of the concatenated images\n",
        "* flatten the spatial dimension of all patches\n",
        "* layer normalize the flattened patches and then project it"
      ],
      "metadata": {
        "id": "31fm3VoXBwGB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ShiftedPatchTokenization(layers.Layer):\n",
        "  def __init__(\n",
        "      self,\n",
        "      image_size=IMAGE_SIZE,\n",
        "      patch_size=PATCH_SIZE,\n",
        "      num_patches=NUM_PATCHES,\n",
        "      projection_dim=PROJECTION_DIM,\n",
        "      vanilla=False,\n",
        "      **kwargs\n",
        "  ):\n",
        "    super().__init__(**kwargs)\n",
        "    self.vanilla = vanilla\n",
        "    self.patch_size = patch_size\n",
        "    self.num_patches = num_patches\n",
        "    self.flatten_patches = layers.Reshape((num_patches, -1))\n",
        "    self.layer_norm = layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.projection = layers.Dense(units=projection_dim)\n",
        "    self.half_patch = self.patch_size // 2\n",
        "\n",
        "  def crop_shift_pad(self, images, mode):\n",
        "    if mode == \"left-up\":\n",
        "      crop_height = self.half_patch\n",
        "      crop_width = self.half_patch\n",
        "      shift_height = 0\n",
        "      shift_width = 0\n",
        "    elif mode == \"left-down\":\n",
        "      crop_height = 0\n",
        "      crop_width = self.half_patch\n",
        "      shift_height = self.half_patch\n",
        "      shift_width = 0\n",
        "    elif mode == \"right-up\":\n",
        "      crop_height = self.half_patch\n",
        "      crop_width = 0\n",
        "      shift_height = 0\n",
        "      shift_width = self.half_patch\n",
        "    elif mode == \"right-down\":\n",
        "      crop_height = 0\n",
        "      crop_width = 0\n",
        "      shift_height = self.half_patch\n",
        "      shift_width = self.half_patch\n",
        "\n",
        "    # Crop the shifted images and pad them\n",
        "    crop = tf.image.crop_to_bounding_box(\n",
        "        images,\n",
        "        offset_height=crop_height,\n",
        "        offset_width=crop_width,\n",
        "        target_height=self.image_size - self.half_patch,\n",
        "        target_width=self.image_size - self.half_patch,\n",
        "    )\n",
        "    shift_pad = tf.image.pad_to_bounding_box(\n",
        "        crop,\n",
        "        offset_height=shift_height,\n",
        "        offset_width=shift_width,\n",
        "        target_height=self.image_size,\n",
        "        target_width=self.image_size,\n",
        "    )\n",
        "    return shift_pad\n",
        "\n",
        "  def call(self, images):\n",
        "    if not self.vanilla:\n",
        "      # concat the shifted patches with the original image along last axis\n",
        "      images = tf.concat(\n",
        "          [\n",
        "              images, \n",
        "              self.crop_shift_pad(images, mode='left-up'),\n",
        "              self.crop_shift_pad(images, mode='left-down'),\n",
        "              self.crop_shift_pad(images, mode='rigth-up'),\n",
        "              self.crop_shift_pad(images, mode='right-down')\n",
        "          ],\n",
        "          axis=-1\n",
        "      )\n",
        "    # Patch generation\n",
        "    patches = tf.image.extract_patches(\n",
        "        images=images,\n",
        "        sizes=[1, self.patch_size, self.patch_size, 1],\n",
        "        strides=[1, self.patch_size, self.patch_size, 1],\n",
        "        rates=[1, 1, 1, 1],\n",
        "        padding='VALID'\n",
        "    )\n",
        "    flat_patches = self.flatten_patches(patches)\n",
        "    if not self.vanilla:\n",
        "      tokens = self.layer_norm(flat_patches)\n",
        "      tokens = self.projection(tokens)\n",
        "    else:\n",
        "      tokens = self.projection(flat_patches)\n",
        "    return (tokens, patches)"
      ],
      "metadata": {
        "id": "QLEKSdmmksQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize the patches"
      ],
      "metadata": {
        "id": "p8KZK86UbUfP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_image = x_train[np.random.choice(range(x_train.shape[0]))]"
      ],
      "metadata": {
        "id": "b7mAp1RqbUNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resized_image = tf.image.resize(\n",
        "    tf.convert_to_tensor([x_image]), size=(IMAGE_SIZE, IMAGE_SIZE)\n",
        ")"
      ],
      "metadata": {
        "id": "grzWc5p-EACn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token, patch = ShiftedPatchTokenization(vanilla=True)(resized_image / 255.0)"
      ],
      "metadata": {
        "id": "5pwoqCWvbmx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(token.shape)\n",
        "print(patch.shape)"
      ],
      "metadata": {
        "id": "ClLXGW3Mb9nD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token, patch = token[0], patch[0]"
      ],
      "metadata": {
        "id": "pgY7Xs21cJVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(x_image / 255.0)"
      ],
      "metadata": {
        "id": "oz2X76lReZ7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(4, 4))\n",
        "index = 1\n",
        "n = patch.shape[0]\n",
        "for row in range(n):\n",
        "  for col in range(n):\n",
        "    plt.subplot(n, n, index)\n",
        "    index += 1\n",
        "    image = tf.reshape(patch[row][col], (PATCH_SIZE, PATCH_SIZE, 3))\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qHZb1DkOcdGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UWoRRSw-d8ef"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}