{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ViT_for_small_datasets",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pf5wzoVhVCnp"
      },
      "outputs": [],
      "source": [
        "pip install -qq -U tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "gazpwBl-VYoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLASSES = 100\n",
        "INPUT_SHAPE = (32, 32, 3)\n",
        "\n",
        "IMAGE_SIZE = 72\n",
        "PATCH_SIZE = 6\n",
        "NUM_PATCHES = (IMAGE_SIZE // PATCH_SIZE) ** 2\n",
        "\n",
        "PROJECTION_DIM = 64"
      ],
      "metadata": {
        "id": "0bJyDGF3VLdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar100.load_data()"
      ],
      "metadata": {
        "id": "jPlk9I3tVTPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data augmentation\n",
        "\n",
        "According to DeiT, various techniqus are required to effectively train ViTs.\n",
        "Thus we applied data augmentations such as CutMix, Mixup, Auto Augment, Repeated Augment to all models."
      ],
      "metadata": {
        "id": "JOx0EPrBV3TK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = tf.keras.Sequential(\n",
        "  [\n",
        "    tf.keras.layers.Normalization(),\n",
        "    tf.keras.layers.Resizing(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    tf.keras.layers.RandomFlip('horizontal'),\n",
        "    tf.keras.layers.RandomRotation(factor=0.2),\n",
        "    tf.keras.layers.RandomZoom(height_factor=0.2, width_factor=0.2),\n",
        "  ],\n",
        "  name='data_augmentation'\n",
        ")\n",
        "# Compute the mean and the variance of the training data for normalization.\n",
        "data_augmentation.layers[0].adapt(x_train)"
      ],
      "metadata": {
        "id": "TU2CyKiwV25m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PatchEncoder"
      ],
      "metadata": {
        "id": "b6MGDuqXjFlw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchEncoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_patches=NUM_PATCHES, projection_dim=PROJECTION_DIM, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.num_patches = num_patches\n",
        "    self.position_embedding = tf.keras.layers.Embedding(\n",
        "        input_dim=num_patches, output_dim=projection_dim\n",
        "    )\n",
        "    self.positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
        "\n",
        "  def call(self, encoded_patches):\n",
        "    encoded_positions = self.position_embedding(self.positions)\n",
        "    encoded_patches = encoded_patches + encoded_positions\n",
        "    return encoded_patches\n",
        "\n"
      ],
      "metadata": {
        "id": "CdLzP_w6VeF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QLEKSdmmksQB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}