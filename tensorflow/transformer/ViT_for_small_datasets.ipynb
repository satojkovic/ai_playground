{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ViT_for_small_datasets",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pf5wzoVhVCnp"
      },
      "outputs": [],
      "source": [
        "pip install -qq -U tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "gazpwBl-VYoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLASSES = 100\n",
        "INPUT_SHAPE = (32, 32, 3)\n",
        "\n",
        "IMAGE_SIZE = 72\n",
        "PATCH_SIZE = 6\n",
        "NUM_PATCHES = (IMAGE_SIZE // PATCH_SIZE) ** 2\n",
        "\n",
        "PROJECTION_DIM = 64"
      ],
      "metadata": {
        "id": "0bJyDGF3VLdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar100.load_data()"
      ],
      "metadata": {
        "id": "jPlk9I3tVTPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data augmentation\n",
        "\n",
        "According to DeiT, various techniqus are required to effectively train ViTs.\n",
        "Thus we applied data augmentations such as CutMix, Mixup, Auto Augment, Repeated Augment to all models."
      ],
      "metadata": {
        "id": "JOx0EPrBV3TK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = tf.keras.Sequential(\n",
        "  [\n",
        "    tf.keras.layers.Normalization(),\n",
        "    tf.keras.layers.Resizing(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    tf.keras.layers.RandomFlip('horizontal'),\n",
        "    tf.keras.layers.RandomRotation(factor=0.2),\n",
        "    tf.keras.layers.RandomZoom(height_factor=0.2, width_factor=0.2),\n",
        "  ],\n",
        "  name='data_augmentation'\n",
        ")\n",
        "# Compute the mean and the variance of the training data for normalization.\n",
        "data_augmentation.layers[0].adapt(x_train)"
      ],
      "metadata": {
        "id": "TU2CyKiwV25m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PatchEncoder"
      ],
      "metadata": {
        "id": "b6MGDuqXjFlw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchEncoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_patches=NUM_PATCHES, projection_dim=PROJECTION_DIM, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.num_patches = num_patches\n",
        "    self.position_embedding = tf.keras.layers.Embedding(\n",
        "        input_dim=num_patches, output_dim=projection_dim\n",
        "    )\n",
        "    self.positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
        "\n",
        "  def call(self, encoded_patches):\n",
        "    encoded_positions = self.position_embedding(self.positions)\n",
        "    encoded_patches = encoded_patches + encoded_positions\n",
        "    return encoded_patches"
      ],
      "metadata": {
        "id": "CdLzP_w6VeF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Shifted patch tokenization\n",
        "\n",
        "* start with an image\n",
        "* shift the image in diagonal direction\n",
        "* concat the diagonally shifted images with the orignal image\n",
        "* extract pathces of the concatenated images\n",
        "* flatten the spatial dimension of all patches\n",
        "* layer normalize the flattened patches and then project it"
      ],
      "metadata": {
        "id": "31fm3VoXBwGB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ShiftedPatchTokenization(layers.Layer):\n",
        "  def __init__(\n",
        "      self,\n",
        "      image_size=IMAGE_SIZE,\n",
        "      patch_size=PATCH_SIZE,\n",
        "      num_patches=NUM_PATCHES,\n",
        "      projection_dim=PROJECTION_DIM,\n",
        "      vanilla=False,\n",
        "      **kwargs\n",
        "  ):\n",
        "    super().__init__(**kwargs)\n",
        "    self.vanilla = vanilla\n",
        "    self.patch_size = patch_size\n",
        "    self.num_patches = num_patches\n",
        "    self.flatten_patches = layers.Reshape((num_patches, -1))\n",
        "    self.layer_norm = layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.projection = layers.Dense(units=projection_dim)\n",
        "\n",
        "  def crop_shift_pad(self, images, mode):\n",
        "    pass\n",
        "  \n",
        "  def call(self, images):\n",
        "    if not self.vanilla:\n",
        "      # concat the shifted patches with the original image along last axis\n",
        "      images = tf.concat(\n",
        "          [\n",
        "              images, \n",
        "              self.crop_shift_pad(images, mode='left-up'),\n",
        "              self.crop_shift_pad(images, mode='left-down'),\n",
        "              self.crop_shift_pad(images, mode='rigth-up'),\n",
        "              self.crop_shift_pad(images, mode='right-down')\n",
        "          ],\n",
        "          axis=-1\n",
        "      )\n",
        "    # Patch generation\n",
        "    patches = tf.image.extract_patches(\n",
        "        images=images,\n",
        "        sizes=[1, self.patch_size, self.patch_size, 1],\n",
        "        strides=[1, self.patch_size, self.patch_size, 1],\n",
        "        rates=[1, 1, 1, 1],\n",
        "        padding='VALID'\n",
        "    )\n",
        "    flat_patches = self.flatten_patches(patches)\n",
        "    if not self.vanilla:\n",
        "      tokens = self.layer_norm(flat_patches)\n",
        "      tokens = self.projection(tokens)\n",
        "    else:\n",
        "      tokens = self.projection(flat_patches)\n",
        "    return (tokens, patches)"
      ],
      "metadata": {
        "id": "QLEKSdmmksQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "grzWc5p-EACn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}