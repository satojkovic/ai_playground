{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FdrxqSLSvw_m"
      },
      "outputs": [],
      "source": [
        "# Install the nightly version of TensorFlow to use the improved\n",
        "# masking support for `tf.keras.layers.MultiHeadAttention`.\n",
        "!pip uninstall -y -q tensorflow keras tensorflow-estimator tensorflow-text\n",
        "!pip install -q tensorflow_datasets\n",
        "!pip install -q -U tensorflow-text tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "import tensorflow_text"
      ],
      "metadata": {
        "id": "8EnTOVEh-p6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset handling"
      ],
      "metadata": {
        "id": "Eq1tZSE3_aax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en', with_info=True, as_supervised=True)"
      ],
      "metadata": {
        "id": "2x_rh-nn_F_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_examples, val_examples = examples['train'], examples['validation']"
      ],
      "metadata": {
        "id": "hVJlkrDb_nOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for pt_examples, en_examples in train_examples.batch(3).take(1):\n",
        "  print('> Examples portuguese')\n",
        "  for pt in pt_examples.numpy():\n",
        "    print(pt.decode('utf-8'))\n",
        "  print()\n",
        "  for en in en_examples.numpy():\n",
        "    print(en.decode('utf-8'))"
      ],
      "metadata": {
        "id": "4MU_vsjh_tFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization"
      ],
      "metadata": {
        "id": "XIzK3EpuGlF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'ted_hrlr_translate_pt_en_converter'\n",
        "tf.keras.utils.get_file(\n",
        "    f'{model_name}.zip',\n",
        "    f'https://storage.googleapis.com/download.tensorflow.org/models/{model_name}.zip',\n",
        "    cache_dir='.', cache_subdir='', extract=True\n",
        ")"
      ],
      "metadata": {
        "id": "sD1PJxLBGkrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizers = tf.saved_model.load(model_name)"
      ],
      "metadata": {
        "id": "ngjhLQf2ANC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[item for item in dir(tokenizers.en) if not item.startswith('_')]"
      ],
      "metadata": {
        "id": "CBG8rZW6HEAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en_examples"
      ],
      "metadata": {
        "id": "5fj5RnlNHMik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded = tokenizers.en.tokenize(en_examples)"
      ],
      "metadata": {
        "id": "t3jwqA1WHZKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded"
      ],
      "metadata": {
        "id": "AYObFFv1Hkfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pt_examples"
      ],
      "metadata": {
        "id": "fABq9iAopYNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_pt = tokenizers.pt.tokenize(pt_examples)"
      ],
      "metadata": {
        "id": "fX6d6tK0pBq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_pt"
      ],
      "metadata": {
        "id": "yxpvjP93pM3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_pt = tokenizers.pt.detokenize(encoded_pt)"
      ],
      "metadata": {
        "id": "jkgSskhypQ8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_pt"
      ],
      "metadata": {
        "id": "qBIS5jp-pVip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lengths = []\n",
        "\n",
        "for pt_examples, en_examples in train_examples.batch(1024):\n",
        "  pt_tokens = tokenizers.pt.tokenize(pt_examples)\n",
        "  lengths.append(pt_tokens.row_lengths())\n",
        "\n",
        "  en_tokens = tokenizers.en.tokenize(en_examples)\n",
        "  lengths.append(en_tokens.row_lengths())"
      ],
      "metadata": {
        "id": "xLN1WtFAHlqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_lengths = np.concatenate(lengths)\n",
        "\n",
        "plt.hist(all_lengths, np.linspace(0, 500, 101))\n",
        "plt.ylim(plt.ylim())\n",
        "max_length = max(all_lengths)\n",
        "plt.plot([max_length, max_length], plt.ylim())\n",
        "plt.title(f'Maximum tokens per example: {max_length}')"
      ],
      "metadata": {
        "id": "uGoPZ04wIgHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup a data pipeline with tf.data"
      ],
      "metadata": {
        "id": "qtSd-eqER922"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_TOKENS = 128\n",
        "def prepare_batch(pt, en):\n",
        "  pt = tokenizers.pt.tokenize(pt)\n",
        "  pt = pt[:, :MAX_TOKENS]\n",
        "  pt = pt.to_tensor() # Convert `RaggedTensor` to 0-padded dense Tensor\n",
        "\n",
        "  en = tokenizers.en.tokenize(en)\n",
        "  en = en[:, :(MAX_TOKENS+1)]\n",
        "  en_inputs = en[:, :-1].to_tensor() # Drop the [END]\n",
        "  en_labels = en[:, 1:].to_tensor() # Drop the [START]\n",
        "\n",
        "  return (pt, en_inputs), en_labels"
      ],
      "metadata": {
        "id": "6b2ZWvxBJMqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = 20000\n",
        "BATCH_SIZE = 64"
      ],
      "metadata": {
        "id": "YAFjXvfcTIDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_batches(ds):\n",
        "  return (\n",
        "      ds\n",
        "      .shuffle(BUFFER_SIZE)\n",
        "      .batch(BATCH_SIZE)\n",
        "      .map(prepare_batch, tf.data.AUTOTUNE)\n",
        "      .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "  )"
      ],
      "metadata": {
        "id": "O3OoCM5XTxRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_batches = make_batches(train_examples)\n",
        "val_batches = make_batches(val_examples)"
      ],
      "metadata": {
        "id": "HoZ9XlR4UCFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for (pt, en), en_labels in train_batches.take(1):\n",
        "  print(pt.shape)\n",
        "  print(en.shape)"
      ],
      "metadata": {
        "id": "u7LwbUIrUIGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Positional Encoding"
      ],
      "metadata": {
        "id": "bkvX_1U-wdKv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def positional_encoding(length, depth):\n",
        "  depth = depth / 2 # => 2/d_model\n",
        "\n",
        "  positions = np.arange(length)[:, np.newaxis] # (hidden_dim, 1)\n",
        "  depths = np.arange(depth)[np.newaxis, :]/depth # (1, depth)\n",
        "\n",
        "  angle_rates = 1 / (10000**depths)\n",
        "  angle_rads = positions * angle_rates\n",
        "\n",
        "  pos_encoding = np.concatenate(\n",
        "      [np.sin(angle_rads), np.cos(angle_rads)],\n",
        "      axis=-1\n",
        "  )\n",
        "\n",
        "  return tf.cast(pos_encoding, dtype=tf.float32)"
      ],
      "metadata": {
        "id": "YY6JR9QYUPG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos_encoding = positional_encoding(length=2048, depth=512)\n",
        "\n",
        "# Check the shape.\n",
        "print(pos_encoding.shape)\n",
        "\n",
        "# Plot the dimensions.\n",
        "plt.pcolormesh(pos_encoding.numpy().T, cmap='RdBu')\n",
        "plt.ylabel('Depth')\n",
        "plt.xlabel('Position')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kNytopp8xjNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos_encoding/=tf.norm(pos_encoding, axis=1, keepdims=True)\n",
        "p = pos_encoding[1000]\n",
        "dots = tf.einsum('pd,d -> p', pos_encoding, p)\n",
        "plt.subplot(2,1,1)\n",
        "plt.plot(dots)\n",
        "plt.ylim([0,1])\n",
        "plt.plot([950, 950, float('nan'), 1050, 1050],\n",
        "         [0,1,float('nan'),0,1], color='k', label='Zoom')\n",
        "plt.legend()\n",
        "plt.subplot(2,1,2)\n",
        "plt.plot(dots)\n",
        "plt.xlim([950, 1050])\n",
        "plt.ylim([0,1])"
      ],
      "metadata": {
        "id": "I6VLG3Qb4gwH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}