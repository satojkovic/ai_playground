{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "detr_example",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.8.0 torchvision==0.9.0 -qq"
      ],
      "metadata": {
        "id": "1bpI-tMeK-kQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "import requests\n",
        "import matplotlib.pyplot as plt\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "import torchvision.transforms as T\n",
        "torch.set_grad_enabled(False)"
      ],
      "metadata": {
        "id": "O2lzJH8IKr8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# COCO classes\n",
        "CLASSES = [\n",
        "    'N/A', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
        "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A',\n",
        "    'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse',\n",
        "    'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack',\n",
        "    'umbrella', 'N/A', 'N/A', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis',\n",
        "    'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove',\n",
        "    'skateboard', 'surfboard', 'tennis racket', 'bottle', 'N/A', 'wine glass',\n",
        "    'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich',\n",
        "    'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake',\n",
        "    'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table', 'N/A',\n",
        "    'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard',\n",
        "    'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A',\n",
        "    'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier',\n",
        "    'toothbrush'\n",
        "]\n",
        "\n",
        "# colors for visualization\n",
        "COLORS = [[0.000, 0.447, 0.741], [0.850, 0.325, 0.098], [0.929, 0.694, 0.125],\n",
        "          [0.494, 0.184, 0.556], [0.466, 0.674, 0.188], [0.301, 0.745, 0.933]]"
      ],
      "metadata": {
        "id": "puLZeXQPRudD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for output bounding box post-processing\n",
        "def box_cxcywh_to_xyxy(x):\n",
        "    x_c, y_c, w, h = x.unbind(1)\n",
        "    b = [(x_c - 0.5 * w), (y_c - 0.5 * h),\n",
        "         (x_c + 0.5 * w), (y_c + 0.5 * h)]\n",
        "    return torch.stack(b, dim=1)\n",
        "\n",
        "def rescale_bboxes(out_bbox, size):\n",
        "    img_w, img_h = size\n",
        "    b = box_cxcywh_to_xyxy(out_bbox)\n",
        "    b = b * torch.tensor([img_w, img_h, img_w, img_h], dtype=torch.float32)\n",
        "    return b\n",
        "\n",
        "def plot_results(pil_img, prob, boxes):\n",
        "    plt.figure(figsize=(16,10))\n",
        "    plt.imshow(pil_img)\n",
        "    ax = plt.gca()\n",
        "    colors = COLORS * 100\n",
        "    for p, (xmin, ymin, xmax, ymax), c in zip(prob, boxes.tolist(), colors):\n",
        "        ax.add_patch(plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,\n",
        "                                   fill=False, color=c, linewidth=3))\n",
        "        cl = p.argmax()\n",
        "        text = f'{CLASSES[cl]}: {p[cl]:0.2f}'\n",
        "        ax.text(xmin, ymin, text, fontsize=15,\n",
        "                bbox=dict(facecolor='yellow', alpha=0.5))\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "v4geh6pSRcb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.hub.load('facebookresearch/detr', 'detr_resnet50', pretrained=True)"
      ],
      "metadata": {
        "id": "01C8TgKNNFiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "id": "7s_EggLuNOJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'http://images.cocodataset.org/val2017/000000039769.jpg'"
      ],
      "metadata": {
        "id": "3kyfkHjlNU0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "im = Image.open(requests.get(url, stream=True).raw)"
      ],
      "metadata": {
        "id": "TP0l82HvNaez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "im"
      ],
      "metadata": {
        "id": "gcn_aKgmNsfU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = T.Compose([\n",
        "  T.Resize(800),\n",
        "  T.ToTensor(),\n",
        "  T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "U0iJohcLNtlz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = transform(im).unsqueeze(0) # unsqueeze"
      ],
      "metadata": {
        "id": "XmTtracDO1sr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model(img)"
      ],
      "metadata": {
        "id": "fauNbbVmO-b9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs.keys()"
      ],
      "metadata": {
        "id": "lUcuCcWyPAG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs['pred_logits'].shape"
      ],
      "metadata": {
        "id": "NxZ3dYP8PaJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(outputs['pred_logits'].softmax(-1).shape)\n",
        "print(outputs['pred_logits'].softmax(-1))"
      ],
      "metadata": {
        "id": "ZhI_VATAPc8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probas = outputs['pred_logits'].softmax(-1)[0, :, :-1] # Why removing last element?"
      ],
      "metadata": {
        "id": "M0gMaH-FQepj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keep = probas.max(-1).values > 0.9"
      ],
      "metadata": {
        "id": "aX5me5N_Q4PA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert boxes from [0; 1] to image scales\n",
        "bboxes_scaled = rescale_bboxes(outputs['pred_boxes'][0, keep], im.size)"
      ],
      "metadata": {
        "id": "utwjGIaGRQr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_results(im, probas[keep], bboxes_scaled)"
      ],
      "metadata": {
        "id": "0T3J4Ex2RnIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Huggingface Detr\n"
      ],
      "metadata": {
        "id": "UqzNJlT6X2FM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install -q git+https://github.com/huggingface/transformers.git\n",
        "!pip install -q transformers\n",
        "!pip install -q timm\n",
        "!pip install torchinfo"
      ],
      "metadata": {
        "id": "6ffzj9_cYklv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DetrFeatureExtractor, DetrForObjectDetection"
      ],
      "metadata": {
        "id": "5LK-GGk4Rpdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as T\n",
        "import timm"
      ],
      "metadata": {
        "id": "HdK_LQmDYb48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Detr(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.feature_extractor = DetrFeatureExtractor.from_pretrained('facebook/detr-resnet-50')\n",
        "    self.model = DetrForObjectDetection.from_pretrained('facebook/detr-resnet-50')\n",
        "\n",
        "  def forward(self, x):\n",
        "    inputs = self.feature_extractor(images=x, return_tensors='pt')\n",
        "    outputs = self.model(**inputs)\n",
        "    return outputs.logits, outputs.pred_boxes"
      ],
      "metadata": {
        "id": "v_8pMcpRm1E7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FeatureExtractor test"
      ],
      "metadata": {
        "id": "QTu5TYAz1Ubl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_extractor = DetrFeatureExtractor.from_pretrained('facebook/detr-resnet-50')"
      ],
      "metadata": {
        "id": "ibHIvkb71Suz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n",
        "image = Image.open(requests.get(url, stream=True).raw)"
      ],
      "metadata": {
        "id": "Z9QfS4S9Yt3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(image))\n",
        "print(image.size)"
      ],
      "metadata": {
        "id": "S-hFZGGR2KPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = feature_extractor(images=image, return_tensors='pt')"
      ],
      "metadata": {
        "id": "Fike2ionZz_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(inputs.keys())\n",
        "# Shorter side is rescaled to 800\n",
        "print(inputs['pixel_values'].shape) # [batch, channel, height, width]\n",
        "print(inputs['pixel_mask'].shape)"
      ],
      "metadata": {
        "id": "hTrIuB-M16GF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DetrObjcetDetrForObjectDetection test"
      ],
      "metadata": {
        "id": "BhbQwgC63FFi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = DetrForObjectDetection.from_pretrained('facebook/detr-resnet-50')"
      ],
      "metadata": {
        "id": "pr4XUCk53En1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model(**inputs)"
      ],
      "metadata": {
        "id": "3ez2MQuO17Uo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs.keys()"
      ],
      "metadata": {
        "id": "7JaA9F7F5QWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'logits = {outputs.logits.shape}')\n",
        "print(f'pred_boxes = {outputs.pred_boxes.shape}')\n",
        "print(f'last_hidden_state = {outputs.last_hidden_state.shape}')\n",
        "print(f'encoder_last_hidden_state = {outputs.encoder_last_hidden_state.shape}')"
      ],
      "metadata": {
        "id": "L77hhwqe5Sea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary\n",
        "summary(model, input_size=(1, 3, 800, 1066))"
      ],
      "metadata": {
        "id": "yPUrwEd0A0lU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baloon dataset"
      ],
      "metadata": {
        "id": "kgmjqWUt-nUY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "\n",
        "!rm -rf VIA2COCO\n",
        "!git clone https://github.com/woctezuma/VIA2COCO\n",
        "\n",
        "%cd VIA2COCO/\n",
        "\n",
        "!git checkout fixes"
      ],
      "metadata": {
        "id": "9xVbgE0Y_Jij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download, decompress the data\n",
        "!wget https://github.com/matterport/Mask_RCNN/releases/download/v2.1/balloon_dataset.zip\n",
        "!unzip balloon_dataset.zip > /dev/null"
      ],
      "metadata": {
        "id": "37F615GI_zwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_class_index = 0 # assume max_class_idx = 1"
      ],
      "metadata": {
        "id": "1o0H90PGAuRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import convert as via2coco\n",
        "\n",
        "data_path = '/content/VIA2COCO/'\n",
        "\n",
        "for keyword in ['train', 'val']:\n",
        "\n",
        "  input_dir = data_path + 'balloon/' + keyword + '/'\n",
        "  input_json = input_dir + 'via_region_data.json'\n",
        "  categories = ['balloon']\n",
        "  super_categories = ['N/A']\n",
        "  output_json = input_dir + 'custom_' + keyword + '.json'\n",
        "\n",
        "  print('Converting {} from VIA format to COCO format'.format(input_json))\n",
        "\n",
        "  coco_dict = via2coco.convert(\n",
        "      imgdir=input_dir,\n",
        "      annpath=input_json,\n",
        "      categories=categories,\n",
        "      super_categories=super_categories,\n",
        "      output_file_name=output_json,\n",
        "      first_class_index=first_class_index,\n",
        "  )"
      ],
      "metadata": {
        "id": "s-8fbIgx__q2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/data/custom/annotations/\n",
        "\n",
        "!mv /content/VIA2COCO/balloon/train/custom_train.json /content/data/custom/annotations/custom_train.json\n",
        "!mv /content/VIA2COCO/balloon/val/custom_val.json /content/data/custom/annotations/custom_val.json\n",
        "\n",
        "!mkdir -p /content/data/custom/train2017/\n",
        "\n",
        "!mv /content/VIA2COCO/balloon/train/*.jpg /content/data/custom/train2017/\n",
        "\n",
        "!mkdir -p /content/data/custom/val2017/\n",
        "\n",
        "!mv /content/VIA2COCO/balloon/val/*.jpg /content/data/custom/val2017/"
      ],
      "metadata": {
        "id": "zz7_WDRuA7EZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import pycocotools.coco as coco\n",
        "from pycocotools.coco import COCO\n",
        "import numpy as np\n",
        "import skimage.io as io\n",
        "import matplotlib.pyplot as plt\n",
        "import pylab\n",
        "pylab.rcParams['figure.figsize'] = (10.0, 8.0)"
      ],
      "metadata": {
        "id": "1oXHqZISBA4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataDir='/content/data/custom/'\n",
        "dataType='train2017'\n",
        "annFile='{}annotations/custom_train.json'.format(dataDir)"
      ],
      "metadata": {
        "id": "kZSjaNcWBIv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize COCO api for instance annotations\n",
        "coco=COCO(annFile)"
      ],
      "metadata": {
        "id": "mZ_6uW9yBLOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load and display image\n",
        "catIds = coco.getCatIds(catNms=['balloon'])\n",
        "imgIds = coco.getImgIds(catIds=catIds )"
      ],
      "metadata": {
        "id": "q1x03l_iBq7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_id = imgIds[np.random.randint(0,len(imgIds))]\n",
        "print('Image id {}'.format(img_id))\n",
        "\n",
        "img = coco.loadImgs(img_id)[0]\n",
        "\n",
        "img_name = '%s/%s/%s'%(dataDir, dataType, img['file_name'])\n",
        "print('Image name: {}'.format(img_name))\n",
        "\n",
        "I = io.imread(img_name)\n",
        "plt.figure()\n",
        "plt.imshow(I)"
      ],
      "metadata": {
        "id": "7kI8I-JfBsx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "annIds = coco.getAnnIds(imgIds=img['id'], catIds=catIds)\n",
        "anns = coco.loadAnns(annIds)\n",
        "\n",
        "plt.imshow(I)\n",
        "coco.showAnns(anns, draw_bbox=True)"
      ],
      "metadata": {
        "id": "CqZfSZvWB1ma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine tune Detr"
      ],
      "metadata": {
        "id": "JRgjenX5JPpa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "\n",
        "!rm -rf detr\n",
        "!git clone https://github.com/woctezuma/detr.git\n",
        "\n",
        "%cd detr/\n",
        "\n",
        "!git checkout finetune"
      ],
      "metadata": {
        "id": "BgeltjUq6Qho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get pretrained weights\n",
        "checkpoint = torch.hub.load_state_dict_from_url(\n",
        "            url='https://dl.fbaipublicfiles.com/detr/detr-r50-e632da11.pth',\n",
        "            map_location='cpu',\n",
        "            check_hash=True)\n",
        "\n",
        "# Remove class weights\n",
        "del checkpoint[\"model\"][\"class_embed.weight\"]\n",
        "del checkpoint[\"model\"][\"class_embed.bias\"]\n",
        "\n",
        "# Save\n",
        "torch.save(checkpoint,\n",
        "           'detr-r50_no-class-head.pth')"
      ],
      "metadata": {
        "id": "QdNo7elpJTiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert(first_class_index in [0, 1])\n",
        "\n",
        "if first_class_index == 0:\n",
        "\n",
        "  # There is one class, balloon, with ID n°0.\n",
        "\n",
        "  num_classes = 1\n",
        "\n",
        "  finetuned_classes = [\n",
        "      'balloon',\n",
        "  ]\n",
        "\n",
        "  # The `no_object` class will be automatically reserved by DETR with ID equal\n",
        "  # to `num_classes`, so ID n°1 here.  \n",
        "\n",
        "else:\n",
        "\n",
        "  # There is one class, balloon, with ID n°1.\n",
        "  #\n",
        "  # However, DETR assumes that indexing starts with 0, as in computer science,\n",
        "  # so there is a dummy class with ID n°0.\n",
        "  # Caveat: this dummy class is not the `no_object` class reserved by DETR.\n",
        "\n",
        "  num_classes = 2\n",
        "\n",
        "  finetuned_classes = [\n",
        "      'N/A', 'balloon',\n",
        "  ]\n",
        "\n",
        "  # The `no_object` class will be automatically reserved by DETR with ID equal\n",
        "  # to `num_classes`, so ID n°2 here.\n",
        "\n",
        "print('First class index: {}'.format(first_class_index))  \n",
        "print('Parameter num_classes: {}'.format(num_classes))\n",
        "print('Fine-tuned classes: {}'.format(finetuned_classes))"
      ],
      "metadata": {
        "id": "aQgt4IwbJYO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/detr/"
      ],
      "metadata": {
        "id": "C5LKEG2iJgAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py \\\n",
        "  --dataset_file \"custom\" \\\n",
        "  --coco_path \"/content/data/custom/\" \\\n",
        "  --output_dir \"outputs\" \\\n",
        "  --resume \"detr-r50_no-class-head.pth\" \\\n",
        "  --num_classes $num_classes \\\n",
        "  --epochs 10"
      ],
      "metadata": {
        "id": "xQMRNgJlJin9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "p_Llyo_tKWYG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}